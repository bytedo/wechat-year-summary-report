"""
ai/weekly.py - å‘¨åº¦åˆ†ææ¨¡å—

åŒ…å«å‘¨åº¦æ‰¹æ¬¡åˆ†æå’Œå¹´åº¦æ€»ç»“ç”ŸæˆåŠŸèƒ½ã€‚
"""

import hashlib
import json
import logging
from pathlib import Path
from typing import List, Tuple

logger = logging.getLogger(__name__)


class WeeklyAnalysisMixin:
    """
    å‘¨åº¦åˆ†ææ··å…¥ç±»ï¼Œæä¾›å‘¨åº¦åˆ†æç›¸å…³æ–¹æ³•ã€‚
    
    éœ€è¦ä¸ AIAnalyzerBase ä¸€èµ·ä½¿ç”¨ã€‚
    """
    
    def analyze_weekly_batches(
        self, 
        weekly_samples: list, 
        use_cache: bool = True
    ) -> Tuple[str, dict]:
        """
        æŒ‰å‘¨æ‰¹æ¬¡åˆ†ææ¶ˆæ¯ï¼Œç”Ÿæˆå¹´åº¦æ·±åº¦æ€»ç»“ã€‚
        
        å‚æ•°:
            weekly_samples: æ¯å‘¨æ¶ˆæ¯æ ·æœ¬åˆ—è¡¨ [{'week': '...', 'messages': [...]}, ...]
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼ˆé»˜è®¤å¼€å¯ï¼‰
            
        è¿”å›:
            (å¹´åº¦æ€»ç»“æ–‡æœ¬, æ¯å‘¨æ€»ç»“å­—å…¸ {'2024-W01': 'æ€»ç»“å†…å®¹...'})
        """
        if not weekly_samples:
            return "", {}
        
        if self.mock_mode:
            return "ï¼ˆMockæ¨¡å¼è·³è¿‡æ·±åº¦å‘¨åº¦åˆ†æï¼‰", {}
        
        # === ç¼“å­˜å¤„ç† ===
        cache_dir = Path(__file__).parent.parent.parent / ".cache"
        cache_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¡ç®—æ•°æ®å“ˆå¸Œï¼ˆç”¨äºåˆ¤æ–­æ•°æ®æ˜¯å¦å˜åŒ–ï¼‰
        cache_key_data = json.dumps([
            {'week': w['week'], 'count': len(w['messages']), 
             'sample': w['messages'][0]['content'][:50] if w['messages'] else ''}
            for w in weekly_samples
        ], ensure_ascii=False, sort_keys=True)
        cache_hash = hashlib.md5(cache_key_data.encode()).hexdigest()[:12]
        cache_file = cache_dir / f"weekly_analysis_{cache_hash}.json"
        
        # å°è¯•è¯»å–ç¼“å­˜
        if use_cache and cache_file.exists():
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cached = json.load(f)
                    print(f"   ğŸ’¾ å·²åŠ è½½å‘¨åº¦åˆ†æç¼“å­˜ ({len(cached.get('weekly_summaries', {}))} å‘¨)")
                    return cached.get('yearly_summary', ''), cached.get('weekly_summaries', {})
            except Exception as e:
                logger.warning(f"ç¼“å­˜è¯»å–å¤±è´¥: {e}")
        
        print(f"   ğŸ§  æ­£åœ¨è¿›è¡Œæ·±åº¦å‘¨åº¦åˆ†æ (å…± {len(weekly_samples)} å‘¨)...")
        
        weekly_summaries_dict = {}
        weekly_summaries_text_list = []
        
        # å°è¯•ä½¿ç”¨ tqdm è¿›åº¦æ¡
        try:
            from tqdm import tqdm
            week_iter = tqdm(weekly_samples, desc="   å‘¨åº¦åˆ†æ", unit="å‘¨", ncols=60)
        except ImportError:
            week_iter = weekly_samples
        
        # æ¯å‘¨å•ç‹¬åˆ†æ (å¸¦è·¨å‘¨ä¸Šä¸‹æ–‡)
        previous_summary = ""  # ç”¨äºè¿è´¯å‰§æƒ…
        for i, week_data in enumerate(week_iter):
            week_label = week_data['week']
            msgs = week_data['messages']
            if not msgs:
                continue
                
            # æ„å»ºæ¶ˆæ¯æ–‡æœ¬ (åªå– user: content) - æ‰©å¤§åˆ° 15000 å­—ç¬¦
            msg_text = "\n".join([f"{m['user']}: {m['content']}" for m in msgs])
            
            # æ„å»ºè·¨å‘¨ä¸Šä¸‹æ–‡
            context_section = ""
            if previous_summary:
                context_section = f"""
## ä¸Šå‘¨å›é¡¾ï¼ˆç”¨äºå‰§æƒ…è¿è´¯ï¼‰ï¼š
{previous_summary[:500]}
---
"""
            
            prompt = f"""ä½ æ˜¯ç¾¤å‹ä»¬çš„å¹´åº¦å›å¿†å®˜ï¼Œæ­£åœ¨ä¸ºå¤§å®¶æ’°å†™ä¸€ä»½èƒ½å‹¾èµ·ç¾å¥½å›å¿†çš„å‘¨æŠ¥ã€‚

{context_section}## {week_label} æœ¬å‘¨æ¶ˆæ¯è®°å½•ï¼š
{msg_text[:15000]}

## å†™ä½œä»»åŠ¡ï¼š
è¯·ç”¨æ¸©æš–ã€æ€€æ—§çš„ç¬”è§¦ï¼Œæ€»ç»“è¿™å‘¨ç¾¤é‡Œçš„æ¸©é¦¨ç¬é—´å’Œæœ‰è¶£æ•…äº‹ã€‚

## å†™ä½œè¦æ±‚ï¼š
1. **å…·ä½“äº‹ä»¶**ï¼šåˆ—å‡º 2-3 ä¸ªè®©äººå°è±¡æ·±åˆ»çš„è¯é¢˜æˆ–æ•…äº‹ï¼Œè¦æœ‰ç»†èŠ‚ï¼ˆè°è¯´äº†ä»€ä¹ˆã€å‘ç”Ÿäº†ä»€ä¹ˆï¼‰
2. **é‡‘å¥æå–**ï¼šæŒ‘é€‰ 1-2 ä¸ªè®©äººä¼šå¿ƒä¸€ç¬‘çš„æ¢—æˆ–é‡‘å¥
3. **å‰§æƒ…è¿è´¯**ï¼šå¦‚æœæœ‰ä¸Šå‘¨å»¶ç»­çš„è¯é¢˜ï¼Œè‡ªç„¶åœ°ä¸²è”èµ·æ¥
4. **æ–‡é£è¦æ±‚**ï¼š
   - åƒè€æœ‹å‹åœ¨å›å¿†å¾€äº‹ï¼Œå¨“å¨“é“æ¥
   - è®©ç¾¤å‹è¯»åˆ°æ—¶èƒ½æƒ³èµ·å½“æ—¶çš„æƒ…æ™¯
   - è¯­æ°”æ¸©æš–å¹½é»˜ï¼Œè®©äººè¯»å®Œå˜´è§’ä¸Šæ‰¬

## â›” ç¦æ­¢äº‹é¡¹ï¼š
- ä¸¥ç¦æåŠåˆ†æ‰‹ã€ç¦»å©šã€å†²çªã€åµæ¶ã€æŠ±æ€¨ç­‰è´Ÿé¢è¯é¢˜
- å¦‚æœæ¶ˆæ¯ä¸­æœ‰è´Ÿé¢å†…å®¹ï¼Œè¯·å¿½ç•¥æˆ–è½¬åŒ–ä¸ºè½»æ¾çš„åæ§½é£æ ¼
- ä¿æŒæ•´ä½“ç§¯æã€æ¸©é¦¨çš„åŸºè°ƒ"""

            try:
                summary = self._call_api(
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ¸©æš–çš„å›å¿†å½•ä½œå®¶ï¼Œæ“…é•¿ä»æ—¥å¸¸å¯¹è¯ä¸­å‘ç°é—ªå…‰æ—¶åˆ»ï¼Œç”¨å……æ»¡æ•…äº‹æ„Ÿçš„æ–‡å­—è®©è¯»è€…é‡æ¸©ç¾å¥½ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.6,
                    max_tokens=500
                )
                weekly_summaries_dict[week_label] = summary
                weekly_summaries_text_list.append(f"### {week_label}\n{summary}")
                previous_summary = summary  # æ›´æ–°è·¨å‘¨ä¸Šä¸‹æ–‡
                print(f"     âœ“ {week_label} åˆ†æå®Œæˆ")
            except Exception as e:
                logger.warning(f"{week_label} åˆ†æå¤±è´¥: {e}")
        
        # æ±‡æ€»æ‰€æœ‰å‘¨æŠ¥ç”Ÿæˆå¹´åº¦æ€»ç»“
        all_summaries = "\n\n".join(weekly_summaries_text_list)
        
        final_prompt = f"""è¿™ä¸€å¹´ï¼Œæˆ‘ä»¬åœ¨ç¾¤é‡Œç•™ä¸‹äº†æ— æ•°æ¸©æš–çš„å›å¿†ã€‚ç°åœ¨ï¼Œè¯·ä¸ºå¤§å®¶å†™ä¸€ä»½è®©äººæƒ³æ¬å‡ºå°æ¿å‡³ç»†ç»†å“è¯»çš„å¹´åº¦å›å¿†å½•ã€‚

## æ¯å‘¨æ‘˜è¦ï¼ˆæ»¡æ»¡çš„å›å¿†ï¼‰ï¼š
{all_summaries}

## ä»»åŠ¡ï¼š
è¯·ç”Ÿæˆä¸€ç¯‡è®©äººè¯»å®Œä¼šå¿ƒå¤´ä¸€æš–çš„å¹´åº¦å›å¿†æ–‡ç« ï¼ˆMarkdownæ ¼å¼ï¼‰ï¼š

### ğŸ¬ å¦‚æœè¿™ä¸€å¹´æ˜¯ä¸€éƒ¨ç”µå½±
ç»™å®ƒèµ·ä¸ªæ¸©æš–çš„åå­—ï¼Œå†™ä¸€æ®µè®©äººå……æ»¡æœŸå¾…çš„"å‰§æƒ…ç®€ä»‹"ï¼ˆ50å­—å·¦å³ï¼‰ã€‚

### ğŸŒŸ å¹´åº¦é«˜å…‰æ—¶åˆ»
åˆ—å‡º 5 ä¸ªæœ€å€¼å¾—çºªå¿µçš„æ¸©é¦¨åœºæ™¯æˆ–æ¬¢ä¹äº‹ä»¶ï¼š
- è¦ç»“åˆå…·ä½“å‘¨çš„å†…å®¹ç»†èŠ‚
- è®©ç¾¤å‹ä»¬èƒ½ç¬¬ä¸€æ—¶é—´æƒ³èµ·å½“æ—¶çš„å¿«ä¹
- ç”¨ç”»é¢æ„Ÿå¼ºçš„è¯­è¨€æè¿°

### ğŸ“œ å‹è°Šç¼–å¹´å²
ç”¨æ—¶é—´çº¿ä¸²èµ·è¿™ä¸€å¹´çš„æ•…äº‹ï¼š
- åƒç»™æœªæ¥çš„è‡ªå·±å†™ä¿¡ä¸€æ ·
- è®°å½•å¤§å®¶çš„å˜åŒ–å’Œæˆé•¿
- çªå‡ºé‚£äº›"åªæœ‰æˆ‘ä»¬æ‡‚"çš„ç¬é—´

### ğŸ’¬ æˆ‘ä»¬çš„ä¸“å±è®°å¿†
é‚£äº›åªæœ‰æˆ‘ä»¬æ‰æ‡‚çš„æ¢—å’Œå£å¤´ç¦…ï¼š
- æ˜¯è¿™ä¸€å¹´å‹è°Šçš„å°è®°
- è®©æ¯ä¸ªè¯»åˆ°çš„äººä¼šå¿ƒä¸€ç¬‘

## å†™ä½œé£æ ¼è¦æ±‚ï¼š
1. **å‹¾èµ·å›å¿†**ï¼šåƒè€æœ‹å‹ç¿»ç€ç›¸å†ŒèŠå¾€äº‹ï¼Œæ¯ä¸ªç»†èŠ‚éƒ½èƒ½è®©äººæƒ³èµ·å½“æ—¶çš„æƒ…æ™¯
2. **æ¸©æƒ…è„‰è„‰**ï¼šå­—é‡Œè¡Œé—´éƒ½æ˜¯å¯¹ç¾¤å‹çš„çè§†ï¼Œè®©è¯»è€…æ„Ÿå—åˆ°"æˆ‘ä»¬æ˜¯ä¸€ä¼™çš„"
3. **å¹½é»˜æš–å¿ƒ**ï¼šå¹½é»˜ä¸­å¸¦ç€æš–æ„ï¼Œè®©äººç¬‘ç€ç¬‘ç€å°±è§‰å¾—å¾ˆå¹¸ç¦
4. **ç»†èŠ‚ä¸ºç‹**ï¼šå¼•ç”¨å…·ä½“çš„äººåã€äº‹ä»¶ã€é‡‘å¥ï¼Œè®©ç¾¤å‹èƒ½ç¬¬ä¸€æ—¶é—´å¯¹å·å…¥åº§

## â›” ç¦æ­¢äº‹é¡¹ï¼š
- ä¸¥ç¦æåŠåˆ†æ‰‹ã€ç¦»å©šã€å†²çªã€åµæ¶ã€æŠ±æ€¨ç­‰è´Ÿé¢è¯é¢˜
- ä¿æŒæ•´ä½“ç§¯æã€æ¸©é¦¨ã€æ€€æ—§çš„åŸºè°ƒ"""

        try:
            print("   ğŸ“ æ­£åœ¨ç”Ÿæˆå¹´åº¦æ·±åº¦æ€»ç»“...")
            content = self._call_api(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ–‡ç¬”ç»†è…»çš„å›å¿†å½•ä½œå®¶ï¼Œæ“…é•¿ç”¨æ¸©æš–æ€€æ—§çš„ç¬”è§¦æŠŠå¹³å‡¡æ—¥å¸¸å†™æˆè®©äººåŠ¨å®¹çš„æ•…äº‹ã€‚ä½ çš„æ–‡å­—èƒ½å‹¾èµ·è¯»è€…å¿ƒåº•æœ€æŸ”è½¯çš„å›å¿†ã€‚"},
                    {"role": "user", "content": final_prompt}
                ],
                temperature=0.75,
                max_tokens=2500
            )
            
            # ä¿å­˜ç¼“å­˜
            if use_cache:
                try:
                    with open(cache_file, 'w', encoding='utf-8') as f:
                        json.dump({
                            'yearly_summary': content,
                            'weekly_summaries': weekly_summaries_dict
                        }, f, ensure_ascii=False, indent=2)
                    print(f"   ğŸ’¾ å‘¨åº¦åˆ†æå·²ç¼“å­˜")
                except Exception as e:
                    logger.warning(f"ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
            
            return content, weekly_summaries_dict
        except Exception as e:
            logger.warning(f"å¹´åº¦æ€»ç»“ç”Ÿæˆå¤±è´¥: {e}")
            return "å¹´åº¦æ€»ç»“ç”Ÿæˆå¤±è´¥", weekly_summaries_dict
