"""
ai_analyzer.py - AI åˆ†æä»£ç†æ¨¡å—

ä½¿ç”¨ LLM å¯¹èŠå¤©æ•°æ®è¿›è¡Œæ·±åº¦åˆ†æï¼ŒåŒ…æ‹¬è¯é¢˜æ€»ç»“ã€ç”¨æˆ·ç”»åƒç­‰ã€‚
æ”¯æŒ Mock æ¨¡å¼ï¼Œå½“æ²¡æœ‰ API Key æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®ã€‚
"""

import os
import random
import re
import time
import logging
from functools import wraps
from typing import List, Optional, Callable, Any

import pandas as pd
from dotenv import load_dotenv

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


def retry_on_failure(max_retries: int = 3, base_delay: float = 1.0, exceptions: tuple = (Exception,)):
    """
    API è°ƒç”¨é‡è¯•è£…é¥°å™¨ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥ã€‚
    
    å‚æ•°:
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        base_delay: åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        exceptions: éœ€è¦æ•è·çš„å¼‚å¸¸ç±»å‹
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            last_exception = None
            for attempt in range(max_retries + 1):
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    if attempt < max_retries:
                        delay = base_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿: 1s, 2s, 4s
                        logger.warning(f"API è°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {e}ï¼Œ{delay:.1f}ç§’åé‡è¯•...")
                        time.sleep(delay)
                    else:
                        logger.error(f"API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
            raise last_exception
        return wrapper
    return decorator


class AIAnalyzer:
    """
    AI åˆ†æå™¨ï¼Œæ”¯æŒ OpenAI å…¼å®¹æ¥å£ï¼ˆDeepSeek/Moonshot ç­‰ï¼‰ã€‚
    
    é€šè¿‡ `LLM_REQUEST_DELAY` ç¯å¢ƒå˜é‡æ§åˆ¶è¯·æ±‚é—´å»¶è¿Ÿï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 2 ç§’ã€‚
    å¢åŠ è¯¥å€¼å¯æœ‰æ•ˆé™ä½ 504 è¶…æ—¶é”™è¯¯å‘ç”Ÿçš„æ¦‚ç‡ã€‚
    """
    
    # è¯·æ±‚é—´å»¶è¿Ÿé…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œé»˜è®¤ 2 ç§’ï¼‰
    REQUEST_DELAY = float(os.getenv('LLM_REQUEST_DELAY', '2.0'))
    
    # ä¸Šæ¬¡è¯·æ±‚æ—¶é—´ï¼ˆç”¨äºè®¡ç®—éœ€è¦ç­‰å¾…çš„æ—¶é—´ï¼‰
    _last_request_time: float = 0
    
    def __init__(self, base_url: str = None, api_key: str = None, model: str = None):
        """
        åˆå§‹åŒ– AI åˆ†æå™¨ã€‚
        
        å‚æ•°:
            base_url: API åŸºç¡€åœ°å€
            api_key: API å¯†é’¥
            model: æ¨¡å‹åç§°
        """
        self.base_url = base_url or os.getenv('LLM_BASE_URL', 'https://api.deepseek.com/v1')
        self.api_key = api_key or os.getenv('LLM_API_KEY', '')
        self.model = model or os.getenv('LLM_MODEL', 'deepseek-chat')
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨ Mock æ¨¡å¼
        self.mock_mode = not self.api_key or self.api_key == 'your-api-key-here'
        
        if not self.mock_mode:
            try:
                from openai import OpenAI
                self.client = OpenAI(
                    base_url=self.base_url,
                    api_key=self.api_key
                )
            except ImportError:
                logger.warning("openai åº“æœªå®‰è£…ï¼Œå¯ç”¨ Mock æ¨¡å¼")
                self.mock_mode = True
    
    def _wait_for_rate_limit(self):
        """
        ç­‰å¾…ä»¥æ»¡è¶³è¯·æ±‚é€Ÿç‡é™åˆ¶ã€‚
        
        ç¡®ä¿ä¸¤æ¬¡ API è°ƒç”¨ä¹‹é—´è‡³å°‘é—´éš” REQUEST_DELAY ç§’ï¼Œ
        é˜²æ­¢å› è¯·æ±‚è¿‡äºå¯†é›†å¯¼è‡´ 504 ç½‘å…³è¶…æ—¶ã€‚
        """
        if AIAnalyzer._last_request_time > 0:
            elapsed = time.time() - AIAnalyzer._last_request_time
            if elapsed < self.REQUEST_DELAY:
                wait_time = self.REQUEST_DELAY - elapsed
                logger.debug(f"é€Ÿç‡é™åˆ¶ï¼šç­‰å¾… {wait_time:.1f} ç§’...")
                time.sleep(wait_time)
    
    def _call_api(
        self,
        messages: List[dict],
        temperature: float = 0.7,
        max_tokens: int = 2000,
        max_retries: int = 3
    ) -> str:
        """
        å¸¦é€Ÿç‡é™åˆ¶å’Œé‡è¯•æœºåˆ¶çš„ API è°ƒç”¨ã€‚
        
        å‚æ•°:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            temperature: ç”Ÿæˆæ¸©åº¦
            max_tokens: æœ€å¤§ token æ•°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        è¿”å›:
            API å“åº”å†…å®¹
        """
        last_exception = None
        
        for attempt in range(max_retries + 1):
            try:
                # è¯·æ±‚å‰ç­‰å¾…ï¼Œæ»¡è¶³é€Ÿç‡é™åˆ¶
                self._wait_for_rate_limit()
                
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
                
                # æ›´æ–°ä¸Šæ¬¡è¯·æ±‚æ—¶é—´
                AIAnalyzer._last_request_time = time.time()
                
                content = self._extract_content(response)
                if content:
                    return content
                raise ValueError("API è¿”å›ç©ºå†…å®¹")
                
            except Exception as e:
                last_exception = e
                error_str = str(e).lower()
                
                # æ£€æµ‹ 504 ç½‘å…³è¶…æ—¶é”™è¯¯ï¼Œé‡‡ç”¨æ›´é•¿çš„é€€é¿æ—¶é—´
                is_504_error = '504' in error_str or 'gateway' in error_str or 'timeout' in error_str
                
                if attempt < max_retries:
                    if is_504_error:
                        # 504 é”™è¯¯ä½¿ç”¨æ›´é•¿çš„é€€é¿æ—¶é—´ (5s, 10s, 15s)
                        delay = 5.0 * (attempt + 1)
                        logger.warning(f"âš ï¸ API 504 è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries + 1}): æœåŠ¡ç«¯ç¹å¿™ï¼Œ{delay:.0f} ç§’åé‡è¯•...")
                    else:
                        # æ™®é€šé”™è¯¯ä½¿ç”¨æŒ‡æ•°é€€é¿ (2s, 4s, 8s)
                        delay = 2.0 * (2 ** attempt)
                        logger.warning(f"API è°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {e}ï¼Œ{delay:.1f} ç§’åé‡è¯•...")
                    
                    time.sleep(delay)
                    
                    # 504 é”™è¯¯åè¿˜éœ€é¢å¤–é‡ç½®é€Ÿç‡é™åˆ¶è®¡æ—¶å™¨
                    if is_504_error:
                        AIAnalyzer._last_request_time = time.time()
                else:
                    logger.error(f"API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
        
        raise last_exception
    
    def analyze(self, df: pd.DataFrame, top_users: List[dict]) -> dict:
        """
        æ‰§è¡Œ AI åˆ†æã€‚
        
        å‚æ•°:
            df: æ¶ˆæ¯æ•°æ® DataFrame
            top_users: æ´»è·ƒç”¨æˆ·åˆ—è¡¨
            
        è¿”å›:
            AI åˆ†æç»“æœå­—å…¸
        """
        if self.mock_mode:
            return self._mock_analyze(top_users)
        
        # é‡‡æ ·æ¶ˆæ¯ç”¨äºåˆ†æ
        sampled_messages = self._sample_messages(df)
        
        # æ„å»ºåˆ†ææç¤º
        prompt = self._build_prompt(sampled_messages, top_users)
        
        try:
            content = self._call_api(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å……æ»¡è¯—æ„ä¸æ¸©æƒ…çš„ç¾¤èŠå›å¿†å®˜ï¼Œåƒè€æœ‹å‹ä¸€æ ·è®°å½•ç€æ¯ä¸€ä¸ªçè´µç¬é—´ã€‚ä½ ç›¸ä¿¡æ¯æ®µå¯¹è¯èƒŒåéƒ½æœ‰æ•…äº‹ï¼Œæ¯ä½ç¾¤å‹éƒ½æ˜¯ç‹¬ä¸€æ— äºŒçš„å­˜åœ¨ã€‚ä½ çš„æ–‡å­—æ¸©æš–å¦‚å†¬æ—¥æš–é˜³ï¼Œè®©è¯»è€…æ„Ÿå—åˆ°å‹è°Šçš„åŠ›é‡ä¸æ—¶å…‰çš„çè´µã€‚ç”¨å¿ƒå‘ç°é‚£äº›çœ‹ä¼¼å¹³å‡¡å´é—ªé—ªå‘å…‰çš„æ—¥å¸¸ï¼Œè®©æ¯ä¸ªäººéƒ½èƒ½åœ¨ä½ çš„æŠ¥å‘Šä¸­æ‰¾åˆ°å±äºè‡ªå·±çš„æ¸©é¦¨è®°å¿†ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            return self._parse_response(content, top_users)
            
        except Exception as e:
            logger.warning(f"AI åˆ†æå¤±è´¥: {e}ï¼Œä½¿ç”¨ Mock æ•°æ®")
            return self._mock_analyze(top_users)
    
    def _sample_messages(self, df: pd.DataFrame, per_month: int = 8, min_length: int = 5) -> List[dict]:
        """
        æŒ‰æœˆå‡åŒ€é‡‡æ ·æ¶ˆæ¯ï¼Œç¡®ä¿æ—¶é—´åˆ†å¸ƒå‡è¡¡ã€‚
        
        å‚æ•°:
            df: æ¶ˆæ¯ DataFrame
            per_month: æ¯æœˆé‡‡æ ·æ¶ˆæ¯æ•°ï¼ˆç¡®ä¿æ—¶é—´å‡åŒ€åˆ†å¸ƒï¼‰
            min_length: æœ€å°æ¶ˆæ¯é•¿åº¦
        """
        sampled = []
        
        # æ·»åŠ æœˆä»½åˆ—
        df = df.copy()
        df['month'] = df['date'].str[:7]  # YYYY-MM
        
        # æŒ‰æœˆä»½åˆ†ç»„é‡‡æ ·
        for month, group in df.groupby('month'):
            # è¿‡æ»¤è¾ƒé•¿çš„æ¶ˆæ¯
            long_messages = group[group['content'].str.len() > min_length]
            
            if long_messages.empty:
                continue
            
            # æ¯æœˆå‡åŒ€é‡‡æ ·
            sample_size = min(per_month, len(long_messages))
            month_sample = long_messages.sample(n=sample_size)
            
            for _, row in month_sample.iterrows():
                # æˆªæ–­æ¶ˆæ¯é•¿åº¦ï¼Œé¿å…è¿‡é•¿å†…å®¹è§¦å‘å®¡æ ¸
                content = self._sanitize_content(row['content'])
                if len(content) > 80:
                    content = content[:80] + '...'
                sampled.append({
                    'user': row['user'],
                    'content': content,
                    'date': row['date']
                })
        
        return sampled
    
    def _sanitize_content(self, text: str) -> str:
        """
        éšç§è„±æ•ï¼šæ›¿æ¢æ‰‹æœºå·ç­‰æ•æ„Ÿä¿¡æ¯ã€‚
        """
        # æ›¿æ¢æ‰‹æœºå·
        text = re.sub(r'1[3-9]\d{9}', '138****0000', text)
        # æ›¿æ¢é‚®ç®±
        text = re.sub(r'[\w.-]+@[\w.-]+\.\w+', '***@**.com', text)
        # æ›¿æ¢èº«ä»½è¯å·
        text = re.sub(r'\d{17}[\dXx]', '****', text)
        
        return text
    
    def _build_prompt(self, messages: List[dict], top_users: List[dict]) -> str:
        """
        æ„å»ºåˆ†ææç¤ºè¯ã€‚
        """
        # æŒ‰æœˆä»½æ•´ç†æ¶ˆæ¯
        from collections import defaultdict
        monthly_msgs = defaultdict(list)
        for m in messages:
            month = m['date'][:7]  # YYYY-MM
            monthly_msgs[month].append(m)
        
        # æ ¼å¼åŒ–æŒ‰æœˆæ¶ˆæ¯ï¼ˆæ¯æœˆæœ€å¤š10æ¡ï¼‰
        msg_sections = []
        for month in sorted(monthly_msgs.keys()):
            month_num = int(month.split('-')[1])
            month_name = f"{month_num}æœˆ"
            month_messages = monthly_msgs[month][:10]
            msg_text = "\n".join([
                f"  - {m['user']}: {m['content']}"
                for m in month_messages
            ])
            msg_sections.append(f"### {month_name}\n{msg_text}")
        
        all_msg_text = "\n\n".join(msg_sections)
        
        # æ ¼å¼åŒ–æ‰€æœ‰ç”¨æˆ·ï¼ˆç”¨äºäººç‰©ç”»åƒï¼‰
        all_user_names = [u['user'] for u in top_users]
        
        # ç”Ÿæˆæœˆä»½åˆ—è¡¨
        months_list = [f"{int(m.split('-')[1])}æœˆ" for m in sorted(monthly_msgs.keys())]
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹å¾®ä¿¡ç¾¤èŠè®°å½•ï¼Œç”Ÿæˆä¸€ä»½å……æ»¡æ¸©æƒ…çš„å¹´åº¦ç¾¤èŠæŠ¥å‘Šã€‚

æƒ³è±¡ä½ æ˜¯è¿™ä¸ªç¾¤çš„è€æœ‹å‹ï¼Œåœ¨å¹´æœ«ç¿»çœ‹è¿‡å»ä¸€å¹´çš„èŠå¤©è®°å½•ï¼Œæƒ³è¦ä¸ºå¤§å®¶å†™ä¸€å°æ¸©æš–çš„å¹´åº¦å›å¿†ä¿¡ã€‚

## ç¾¤èŠæ¶ˆæ¯æ ·æœ¬ï¼ˆæŒ‰æœˆæ•´ç†ï¼‰:
{all_msg_text}

## ç¾¤æˆå‘˜åˆ—è¡¨: {', '.join(all_user_names)}
## åŒ…å«æœˆä»½: {', '.join(months_list)}

---

## åˆ†æä»»åŠ¡

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡º Markdown æŠ¥å‘Šï¼š

### ğŸ¯ ç¾¤èŠå¹´åº¦å…³é”®è¯
ç”¨ 3 ä¸ªèƒ½è§¦åŠ¨äººå¿ƒçš„å…³é”®è¯æ€»ç»“è¿™ä¸ªç¾¤çš„æ°›å›´ï¼ˆå¦‚ï¼šé™ªä¼´ã€æ¸©æš–ã€æˆé•¿ã€æ¬¢ç¬‘ç­‰ï¼‰ã€‚
è¿™äº›å…³é”®è¯åº”è¯¥è®©ç¾¤å‹ä»¬çœ‹åˆ°æ—¶ä¼šå¿ƒä¸€ç¬‘ï¼Œæƒ³èµ·é‚£äº›ç¾å¥½çš„æ—¥å­ã€‚

### ğŸ‘¥ ç¾¤å‹ç”»åƒå¢™
ä¸º**æ¯ä¸€ä½**ç¾¤æˆå‘˜ç”Ÿæˆä¸€å¥æ¸©æš–çš„ç”»åƒï¼ˆåŒ…æ‹¬ï¼š{', '.join(all_user_names)}ï¼‰ã€‚
- ç”¨æ¸©æŸ”ã€æ¬£èµçš„è¯­æ°”ï¼Œåƒæ˜¯åœ¨ä»‹ç»è‡ªå·±çè§†çš„æœ‹å‹
- å‘ç°å¹¶æ”¾å¤§æ¯ä¸ªäººèº«ä¸Šçš„é—ªå…‰ç‚¹ï¼Œè®© TA æ„Ÿå—åˆ°è¢«çœ‹è§
- ç»™æ¯äººä¸€ä¸ªå¸¦æœ‰æ¸©åº¦çš„"ç§°å·"ï¼ˆå¦‚ï¼šæ·±å¤œé™ªèŠå®¶ã€ç¾¤èŠå°å¤ªé˜³ã€æ°¸è¿œåœ¨çº¿çš„å€¾å¬è€…ç­‰ï¼‰
- è®©æ¯ä¸ªäººè¯»åˆ°è‡ªå·±çš„ç”»åƒæ—¶ï¼Œéƒ½èƒ½æ„Ÿå—åˆ°ç¾¤å‹ä»¬çš„å–œçˆ±

### ğŸ“… æœˆåº¦è¯é¢˜å›é¡¾
è¯·ä¸º**æ¯ä¸€ä¸ªæœˆ**ï¼ˆ{', '.join(months_list)}ï¼‰éƒ½ç”Ÿæˆè¯¦ç»†çš„è¯é¢˜å›é¡¾ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

**ğŸ“Œ 1æœˆ**
- ğŸ”¹ è¯é¢˜1ï¼šç®€çŸ­æè¿°ï¼ˆ1-2å¥è¯è¯´æ˜å¤§å®¶èŠäº†ä»€ä¹ˆï¼Œè¦æœ‰æ•…äº‹æ„Ÿï¼‰
- ğŸ”¹ è¯é¢˜2ï¼šç®€çŸ­æè¿°
- ğŸ”¹ è¯é¢˜3ï¼šç®€çŸ­æè¿°

**ğŸ“Œ 2æœˆ**
...ï¼ˆä»¥æ­¤ç±»æ¨ï¼Œæ¯ä¸ªæœˆéƒ½è¦æœ‰ 2-4 ä¸ªè¯é¢˜ï¼‰

**âš ï¸ æ¯ä¸ªæœˆéƒ½å¿…é¡»æœ‰å†…å®¹ï¼Œä¸èƒ½è·³è¿‡ä»»ä½•æœˆä»½ï¼**

### âœ¨ å¹´åº¦æ¸©é¦¨æ—¶åˆ»
æŒ‘é€‰ 2-3 ä¸ªæœ€èƒ½ä½“ç°ç¾¤å‹æƒ…è°Šçš„**æ¸©é¦¨ç¬é—´**ï¼Œå¯ä»¥æ˜¯ï¼š
- æœ‰äººé‡åˆ°å›°éš¾æ—¶ï¼Œå¤§å®¶é½å¿ƒå¸®å¿™çš„åœºæ™¯
- æ·±å¤œè¿˜æœ‰äººé™ªèŠçš„æ¸©æš–
- è®©å¤§å®¶ç¬‘å‡ºå£°çš„æœ‰è¶£å¯¹è¯
- èŠ‚æ—¥é‡Œäº’ç›¸ç¥ç¦çš„æ¸©æƒ…

---

## âš ï¸ é‡è¦è§„åˆ™
1. **ç”¨å¿ƒå†™**ï¼šæƒ³è±¡ä½ åœ¨ç»™æœ€å¥½çš„æœ‹å‹ä»¬å†™å¹´ç»ˆä¿¡ï¼Œå­—é‡Œè¡Œé—´éƒ½æ˜¯çœŸæŒšçš„æƒ…æ„Ÿ
2. **æœ‰æ¸©åº¦**ï¼šè®©æ¯å¥è¯éƒ½èƒ½è®©è¯»è€…æ„Ÿå—åˆ°ç¾¤èŠçš„æ¸©æš–å’Œå½’å±æ„Ÿ
3. **è®²æ•…äº‹**ï¼šä¸æ˜¯å¹²å·´å·´åœ°åˆ—æ¸…å•ï¼Œè€Œæ˜¯ç”¨æ•…äº‹ä¸²è”èµ·è¿™ä¸€å¹´çš„å›å¿†
4. **æ¯ä¸ªäººéƒ½é‡è¦**ï¼šç¡®ä¿æ¯ä¸ªäººéƒ½æœ‰ç”»åƒï¼Œè®©å¤§å®¶éƒ½æ„Ÿå—åˆ°è¢«çè§†
5. **é¿å¼€æ•æ„Ÿè¯é¢˜**ï¼šç”¨"æ—¥å¸¸è¶£äº‹"ç­‰æ¦‚æ‹¬æ€§æè¿°æ›¿ä»£ä¸é€‚åˆå…¬å¼€çš„å†…å®¹
6. **æ­£å‘ç§¯æ**ï¼šå³ä½¿æ˜¯åæ§½ï¼Œä¹Ÿè¦è½¬åŒ–ä¸ºè½»æ¾æœ‰è¶£çš„å›å¿†
"""
        return prompt
    
    def _extract_content(self, response) -> str:
        """
        ä»ä¸åŒæ ¼å¼çš„ API å“åº”ä¸­æå–å†…å®¹ã€‚
        æ”¯æŒï¼šOpenAI æ ‡å‡†æ ¼å¼ã€å­—ç¬¦ä¸²ã€å­—å…¸ç­‰å¤šç§æ ¼å¼ã€‚
        """
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
        if isinstance(response, str):
            return response
        
        # æ ‡å‡† OpenAI æ ¼å¼
        if hasattr(response, 'choices') and response.choices:
            choice = response.choices[0]
            if hasattr(choice, 'message') and hasattr(choice.message, 'content'):
                return choice.message.content
            if hasattr(choice, 'text'):
                return choice.text
        
        # å­—å…¸æ ¼å¼
        if isinstance(response, dict):
            # OpenAI æ ¼å¼çš„å­—å…¸
            if 'choices' in response and response['choices']:
                choice = response['choices'][0]
                if isinstance(choice, dict):
                    if 'message' in choice and 'content' in choice['message']:
                        return choice['message']['content']
                    if 'text' in choice:
                        return choice['text']
            # ç›´æ¥æœ‰ content å­—æ®µ
            if 'content' in response:
                return response['content']
            # ç›´æ¥æœ‰ text å­—æ®µ
            if 'text' in response:
                return response['text']
        
        # å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        return str(response) if response else None
    
    def _parse_response(self, content: str, top_users: List[dict]) -> dict:
        """
        è§£æ AI å“åº”ã€‚
        """
        return {
            'raw_content': content,
            'keywords': self._extract_keywords(content),
            'user_profiles': self._extract_user_profiles(content, top_users),
            'topics': self._extract_topics(content),
            'highlights': self._extract_highlights(content),
        }
    
    def _extract_keywords(self, content: str) -> List[str]:
        """å°è¯•ä»å†…å®¹ä¸­æå–å…³é”®è¯"""
        # ç®€å•å®ç°ï¼Œå®é™…å¯ä»¥ç”¨æ›´ç²¾ç¡®çš„åŒ¹é…
        keywords = ['æ¬¢ä¹', 'åæ§½', 'äº’åŠ©']
        return keywords
    
    def _extract_user_profiles(self, content: str, top_users: List[dict]) -> List[dict]:
        """å°è¯•æå–ç”¨æˆ·ç”»åƒ"""
        profiles = []
        for user in top_users[:3]:
            profiles.append({
                'user': user['user'],
                'description': 'ç¾¤å†…æ´»è·ƒåˆ†å­ï¼Œè¯é¢˜å‘èµ·è€…'
            })
        return profiles
    
    def _extract_topics(self, content: str) -> List[str]:
        """å°è¯•æå–è¯é¢˜"""
        return ['æ—¥å¸¸é—²èŠ', 'å·¥ä½œåæ§½', 'ç”Ÿæ´»åˆ†äº«']
    
    def _extract_highlights(self, content: str) -> str:
        """æå–ç²¾å½©ç‰‡æ®µ"""
        return 'ç¾¤å‹ä»¬çš„æ—¥å¸¸æ¬¢ä¹æ—¶å…‰~'
    
    def _mock_analyze(self, top_users: List[dict]) -> dict:
        """
        Mock æ¨¡å¼ï¼šè¿”å›æ¨¡æ‹Ÿæ•°æ®ã€‚
        """
        user_names = [u['user'] for u in top_users[:3]]
        
        mock_content = f"""## ğŸ¯ ç¾¤èŠå¹´åº¦å…³é”®è¯

**é™ªä¼´** | **æ¸©æš–** | **ä¸€èµ·ç¬‘**

è¿™ä¸€å¹´ï¼Œæˆ‘ä»¬ç”¨æ–‡å­—æ­å»ºèµ·ä¸€åº§æ¸©æš–çš„å°å±‹â€”â€”åœ¨è¿™é‡Œï¼Œæœ‰äººåˆ†äº«å–œæ‚¦ï¼Œæœ‰äººå€¾è¯‰çƒ¦æ¼ï¼Œæ›´å¤šçš„æ˜¯äº’ç›¸é™ªä¼´ã€ä¸€èµ·æˆé•¿çš„æ—¥å¸¸ã€‚

---

## ğŸ‘¥ æˆ‘ä»¬çš„å®è—ç¾¤å‹

{"" if not user_names else f'''
### ğŸ¥‡ {user_names[0] if len(user_names) > 0 else "ç¥ç§˜äºº"}
ç¾¤é‡Œçš„å°å¤ªé˜³ï¼Œæ¯å¤©å‡†æ—¶ç»™å¤§å®¶å¸¦æ¥å…ƒæ°”ã€‚æœ‰ TA çš„åœ°æ–¹ï¼Œå°±æœ‰æ¬¢å£°ç¬‘è¯­ã€‚è°¢è°¢ä½ ï¼Œæ€»æ˜¯ç¬¬ä¸€ä¸ªå†’æ³¡ï¼Œè®©ç¾¤é‡Œæ°¸è¿œä¸å†·æ¸…ï¼

### ğŸ¥ˆ {user_names[1] if len(user_names) > 1 else "éšè—å¤§ä½¬"}  
æ·±å¤œçš„æš–å¿ƒé™ªä¼´è€…ï¼Œæ€»åœ¨å¤§å®¶éœ€è¦çš„æ—¶å€™å‡ºç°ã€‚è™½ç„¶è¯ä¸å¤šï¼Œä½†æ¯ä¸€å¥éƒ½æ°åˆ°å¥½å¤„ï¼Œæ˜¯æˆ‘ä»¬çš„å®šå¿ƒä¸¸ã€‚

### ğŸ¥‰ {user_names[2] if len(user_names) > 2 else "æ½œæ°´è¾¾äºº"}
å¿«ä¹çš„ä¼ æ’­è€…ï¼Œè¡¨æƒ…åŒ…é€‰æ‰‹ã€‚æ€»èƒ½åœ¨æ°å½“çš„æ—¶åˆ»ç”¨ä¸€ä¸ªè¡¨æƒ…åŒ…åŒ–è§£å°´å°¬ã€ç‚¹ç‡ƒæ°”æ°›ï¼Œç¾¤é‡Œçš„å¼€å¿ƒæœï¼
'''}

---

## ï¿½ æˆ‘ä»¬çš„æ¸©é¦¨æ—¥å¸¸

1. **æ—©å®‰æ™šå®‰** - æ¯ä¸€å¤©ï¼Œéƒ½æœ‰äººåœ¨ç¾¤é‡Œè¯´"æ—©"ï¼Œè¿™ä»½åšæŒæœ¬èº«å°±å¾ˆæ¸©æš–
2. **æ·±å¤œé™ªèŠ** - ä¸ç®¡å¤šæ™šï¼Œæ€»æœ‰äººæ„¿æ„å¬ä½ è¯´è¯ï¼Œè¿™å°±æ˜¯å‹æƒ…
3. **äº’ç›¸æ‰“æ°”** - å·¥ä½œç´¯äº†ã€ç”Ÿæ´»çƒ¦äº†ï¼Œç¾¤é‡Œæ€»æœ‰äººç»™ä½ åŠ æ²¹æ‰“æ°”
4. **ä¸€èµ·ç¬‘** - é‚£äº›è®©æˆ‘ä»¬ç¬‘åˆ°è‚šå­ç–¼çš„ç¬é—´ï¼Œæ˜¯è¿™ä¸€å¹´æœ€çè´µçš„è®°å¿†
5. **é»˜é»˜å…³å¿ƒ** - æœ‰äººè¯·å‡æ²¡å†’æ³¡ï¼Œæ€»ä¼šæœ‰äººé—®ä¸€å¥"æœ€è¿‘è¿˜å¥½å—"

---

## âœ¨ å¹´åº¦æ¸©é¦¨æ—¶åˆ»

> "æœ€è®©äººæ„ŸåŠ¨çš„ï¼Œæ˜¯æŸä¸ªæ·±å¤œæœ‰äººè¯´'ç¡ä¸ç€'ï¼Œé©¬ä¸Šå°±æœ‰äººå›'æˆ‘ä¹Ÿæ˜¯ï¼ŒèŠèŠï¼Ÿ'

> éš”ç€å±å¹•ï¼Œæˆ‘ä»¬ä¹Ÿèƒ½æ„Ÿå—åˆ°å½¼æ­¤çš„æ¸©åº¦ã€‚"

è¿™ä¸€å¹´ï¼Œæ„Ÿè°¢æœ‰ä½ ä»¬ã€‚ä¸ç®¡æœªæ¥æ€æ ·ï¼Œè¿™ä»½å‹æƒ…ï¼Œæˆ‘ä»¬ä¼šä¸€ç›´è®°å¾—ã€‚â¤ï¸

---

*ï¼ˆè¿™ä»½æŠ¥å‘Šæˆ–è®¸ç®€å•ï¼Œä½†æ¯ä¸€ä¸ªå­—éƒ½æ‰¿è½½ç€æˆ‘ä»¬å…±åŒçš„å›å¿†ï¼‰*
"""
        
        return {
            'raw_content': mock_content,
            'keywords': ['æ¬¢ä¹', 'åæ§½', 'äº’å¸®äº’åŠ©'],
            'user_profiles': [
                {'user': user_names[0] if user_names else 'ç”¨æˆ·1', 'description': 'ç¾¤å†…è¯ç—¨æ‹…å½“'},
                {'user': user_names[1] if len(user_names) > 1 else 'ç”¨æˆ·2', 'description': 'æ·±å¤œå†²æµªé€‰æ‰‹'},
                {'user': user_names[2] if len(user_names) > 2 else 'ç”¨æˆ·3', 'description': 'è¡¨æƒ…åŒ…å¤§å¸ˆ'},
            ],
            'topics': ['æ—¥å¸¸æ‰“å¡', 'ç¾é£Ÿåˆ†äº«', 'å·¥ä½œåæ§½', 'æ¸¸æˆå¼€é»‘', 'ç”Ÿæ´»çäº‹'],
            'highlights': 'ä»Šå¹´æœ€éš¾å¿˜çš„ä¸€åˆ»...',
            'is_mock': True
        }
    
    def summarize_clusters(self, cluster_representatives: dict) -> dict:
        """
        ä½¿ç”¨ LLM ä¸ºèšç±»ç”Ÿæˆæœ‰æ„ä¹‰çš„è¯é¢˜åç§°ã€‚
        
        å‚æ•°:
            cluster_representatives: æ¯ä¸ªèšç±»çš„ä»£è¡¨æ€§æ¶ˆæ¯
                {0: [{'content': '...', 'user': '...'}, ...], 1: [...], ...}
                
        è¿”å›:
            è¯é¢˜åç§°å­—å…¸ {0: 'è¯é¢˜å', 1: 'è¯é¢˜å', ...}
        """
        if self.mock_mode:
            return self._mock_summarize_clusters(cluster_representatives)
        
        # æ„å»º Prompt
        prompt = self._build_cluster_prompt(cluster_representatives)
        
        try:
            content = self._call_api(
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ç¾¤èŠæ˜Ÿç³»çš„å‘½åå¤§å¸ˆï¼Œæ“…é•¿ç”¨ç”µå½±ç‰‡åæˆ–å°è¯´ç« èŠ‚çš„é£æ ¼ä¸ºè¯é¢˜ç»„èµ·åã€‚ä½ çš„åå­—è¦æœ‰æ•…äº‹æ„Ÿã€ç”»é¢æ„Ÿï¼Œèƒ½è®©ç¾¤å‹ä¸€çœ‹å°±æƒ³èµ·é‚£äº›ç¾å¥½æ—¶å…‰ã€‚ä¸¥ç¦ä½¿ç”¨åŠŸèƒ½æ€§ã€äº‹åŠ¡æ€§ã€è´Ÿé¢çš„å‘½åã€‚"
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            return self._parse_cluster_names(content, cluster_representatives)
            
        except Exception as e:
            logger.warning(f"è¯é¢˜å‘½åå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤åç§°")
            return self._mock_summarize_clusters(cluster_representatives)
    
    def _build_cluster_prompt(self, cluster_representatives: dict) -> str:
        """æ„å»ºèšç±»å‘½åçš„æç¤ºè¯ã€‚"""
        lines = ["ä»¥ä¸‹æ˜¯é€šè¿‡å‘é‡ç®—æ³•è‡ªåŠ¨èšç±»çš„ç¾¤èŠæ¶ˆæ¯ç»„ï¼Œè¯·ä¸ºæ¯ç»„èµ·ä¸€ä¸ªå……æ»¡æ•…äº‹æ„Ÿçš„åå­—ã€‚\n"]
        
        for cluster_id, messages in cluster_representatives.items():
            if not messages:
                continue
            
            lines.append(f"## åˆ†ç»„ {cluster_id}")
            for msg in messages[:8]:  # æ¯ç»„å±•ç¤º8æ¡å¢åŠ ç†è§£
                content = msg['content'][:80]  # æˆªæ–­é•¿å†…å®¹
                lines.append(f"- {msg['user']}: {content}")
            lines.append("")
        
        lines.append("""
è¯·è¿”å› JSON æ ¼å¼çš„ç»“æœï¼Œä¾‹å¦‚ï¼š
{"0": "æ·±å¤œé£Ÿå ‚", "1": "åˆåæ‘¸é±¼æ—¶å…‰", "2": "å‘¨æœ«å¥‡é‡è®°"}

## å‘½åé£æ ¼è¦æ±‚ï¼š
- **åƒç”µå½±ç‰‡å**ï¼šæœ‰ç”»é¢æ„Ÿã€æ•…äº‹æ„Ÿï¼ˆå¦‚"æ·±å¤œé£Ÿå ‚"ã€"é‚£äº›å¹´æˆ‘ä»¬ä¸€èµ·è¿½çš„å‰§"ï¼‰
- **åƒå°è¯´ç« èŠ‚**ï¼šæ¸©é¦¨æœ‰è¶£ï¼ˆå¦‚"åˆåæ‘¸é±¼æ—¶å…‰"ã€"æ‰“å·¥äººçš„æ—¥å¸¸"ï¼‰
- **ç®€çŸ­æœ‰åŠ›**ï¼š2-6ä¸ªå­—ï¼Œæœ—æœ—ä¸Šå£
- **å‹¾èµ·å›å¿†**ï¼šè®©ç¾¤å‹ä¸€çœ‹å°±èƒ½æƒ³èµ·é‚£äº›å¯¹è¯

## â›” ç¦æ­¢ä½¿ç”¨ï¼š
- åŠŸèƒ½æ€§å‘½åï¼ˆå¦‚"éœ€æ±‚æ‹›å‹Ÿ"ã€"é—®é¢˜è§£ç­”"ã€"ä¿¡æ¯å’¨è¯¢"ï¼‰
- æŠ½è±¡å‘½åï¼ˆå¦‚"éš¾ä»¥å¯é½¿"ã€"æ·±åº¦äº¤æµ"ã€"ç»¼åˆè®¨è®º"ï¼‰
- è´Ÿé¢å‘½åï¼ˆå¦‚"åˆ†æ‰‹"ã€"åæ§½"ã€"æŠ±æ€¨"ã€"å†²çª"ï¼‰""")
        
        return "\n".join(lines)
    
    def _parse_cluster_names(self, content: str, cluster_representatives: dict) -> dict:
        """è§£æ LLM è¿”å›çš„è¯é¢˜åç§°ã€‚"""
        import json
        
        # å°è¯•æå– JSON
        try:
            # å°è¯•ç›´æ¥è§£æ
            names = json.loads(content)
            return {int(k): v for k, v in names.items()}
        except:
            pass
        
        # å°è¯•ä»æ–‡æœ¬ä¸­æå– JSON å—
        import re
        json_match = re.search(r'\{[^{}]+\}', content)
        if json_match:
            try:
                names = json.loads(json_match.group())
                return {int(k): v for k, v in names.items()}
            except:
                pass
        
        # å¤±è´¥åˆ™è¿”å›é»˜è®¤åç§°
        return self._mock_summarize_clusters(cluster_representatives)
    
    def _mock_summarize_clusters(self, cluster_representatives: dict) -> dict:
        """Mock æ¨¡å¼ï¼šè¿”å›é»˜è®¤è¯é¢˜åç§°ã€‚"""
        default_names = [
            "æ—¥å¸¸é—²èŠ", "æŠ€æœ¯äº¤æµ", "åˆé¤æ‹¼å•",
            "åæ§½å¤§ä¼š", "è¡¨æƒ…åŒ…äº’åŠ¨", "æ·±å¤œemo",
            "æ‘¸é±¼æ—¶é—´", "å‘¨æœ«è®¡åˆ’", "ç”Ÿæ´»åˆ†äº«"
        ]
        
        result = {}
        for i, cluster_id in enumerate(cluster_representatives.keys()):
            name = default_names[i % len(default_names)]
            result[cluster_id] = name
        
        return result
    
    def refine_keywords(self, raw_keywords: list, sample_messages: list = None) -> list:
        """
        ä½¿ç”¨ AI ç­›é€‰å¹¶ä¼˜åŒ–å¹´åº¦å…³é”®è¯ã€‚
        
        å‚æ•°:
            raw_keywords: jieba åˆ†è¯åçš„é«˜é¢‘è¯åˆ—è¡¨ [{'word': '...', 'count': N}, ...]
            sample_messages: å¯é€‰ï¼Œæ¶ˆæ¯æ ·æœ¬ç”¨äºä¸Šä¸‹æ–‡ç†è§£
            
        è¿”å›:
            [{'word': 'å…³é”®è¯'}, ...]
        """
        if not raw_keywords:
            return []
        
        if self.mock_mode:
            return self._mock_refine_keywords(raw_keywords)
        
        # æå–è¯è¯­åˆ—è¡¨
        words_text = "ã€".join([f"{kw['word']}({kw['count']}æ¬¡)" for kw in raw_keywords[:50]])
        
        prompt = f"""è¯·ä»ä»¥ä¸‹é«˜é¢‘è¯ä¸­ç­›é€‰å‡º **8-12 ä¸ª** æœ€èƒ½ä»£è¡¨ç¾¤èŠå¹´åº¦ç‰¹è‰²çš„å…³é”®è¯ã€‚

## å€™é€‰é«˜é¢‘è¯ï¼ˆæŒ‰å‡ºç°æ¬¡æ•°ï¼‰ï¼š
{words_text}

## ç­›é€‰æ ‡å‡†ï¼š
1. **æœ‰æ„ä¹‰çš„è¯è¯­**ï¼šåè¯ã€åŠ¨è¯ã€å½¢å®¹è¯ï¼Œèƒ½è®©äººè”æƒ³åˆ°å…·ä½“åœºæ™¯
2. **ç¾¤èŠç‰¹è‰²è¯**ï¼šèƒ½ä½“ç°ç¾¤å‹ä»¬å…±åŒè¯é¢˜ã€ä¹ æƒ¯æˆ–è®°å¿†çš„è¯
3. **æ’é™¤æ— æ„ä¹‰è¯**ï¼šå¦‚"ä¸€ä¸ª"ã€"ç„¶å"ã€"è¿™ä¸ª"ã€"ä»€ä¹ˆ"ç­‰å£æ°´è¯
4. **æ’é™¤è¿‡äºé€šç”¨çš„è¯**ï¼šå¦‚"çŸ¥é“"ã€"å¯ä»¥"ã€"æ²¡æœ‰"ç­‰

## è¾“å‡ºæ ¼å¼ï¼š
ç›´æ¥è¿”å›ä¸€ä¸ª JSON å­—ç¬¦ä¸²æ•°ç»„ï¼Œä¾‹å¦‚ï¼š
["åŠ ç­", "å¥¶èŒ¶", "æ‘¸é±¼", "å¼€ä¼š", "å‘¨æœ«"]

è¯·ç­›é€‰å‡ºæœ€èƒ½å”¤èµ·ç¾¤å‹å›å¿†çš„è¯è¯­ï¼š"""
        
        try:
            content = self._call_api(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ç¾¤èŠå¹´åº¦å›å¿†ç¼–è¾‘ï¼Œæ“…é•¿ä»é«˜é¢‘è¯ä¸­å‘ç°èƒ½å”¤èµ·ç¾¤å‹å…±åŒå›å¿†çš„å…³é”®è¯ã€‚åªè¾“å‡ºJSONå­—ç¬¦ä¸²æ•°ç»„ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=200
            )
            
            # è§£æ JSON
            import json
            import re
            json_match = re.search(r'\[[\s\S]*\]', content)
            if json_match:
                words = json.loads(json_match.group())
                # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
                return [{'word': w} for w in words[:12] if isinstance(w, str)]
            
        except Exception as e:
            logger.warning(f"å…³é”®è¯ç­›é€‰å¤±è´¥: {e}")
        
        return self._mock_refine_keywords(raw_keywords)
    
    def _mock_refine_keywords(self, raw_keywords: list) -> list:
        """Mock æ¨¡å¼ï¼šç®€å•è¿‡æ»¤è¿”å›"""
        # ç®€å•è¿‡æ»¤ï¼Œå»é™¤å¤ªçŸ­æˆ–å¤ªé€šç”¨çš„è¯
        stopwords = {'ä¸€ä¸ª', 'è¿™ä¸ª', 'é‚£ä¸ª', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'å¯ä»¥', 'æ²¡æœ‰', 'çŸ¥é“', 'ç„¶å', 'ç°åœ¨', 'æ—¶å€™', 'å› ä¸º', 'æ‰€ä»¥', 'ä½†æ˜¯', 'è¿˜æ˜¯', 'å·²ç»', 'å°±æ˜¯', 'ä¸æ˜¯', 'çœŸçš„', 'è§‰å¾—'}
        filtered = [
            {'word': kw['word']}
            for kw in raw_keywords[:15]
            if kw['word'] not in stopwords and len(kw['word']) >= 2
        ]
        return filtered[:10]
    
    def select_golden_quotes(self, hot_messages: list) -> list:
        """
        ä½¿ç”¨ AI ä»çƒ­é—¨æ¶ˆæ¯ä¸­ç”„é€‰é‡‘å¥ã€‚
        
        å‚æ•°:
            hot_messages: çƒ­é—¨æ¶ˆæ¯åˆ—è¡¨ï¼ˆæ¥è‡ª stats_engineï¼‰
            
        è¿”å›:
            [{'user': 'ç”¨æˆ·', 'content': 'é‡‘å¥', 'reason': 'å…¥é€‰ç†ç”±'}, ...]
        """
        if not hot_messages:
            return []
        
        if self.mock_mode:
            return self._mock_golden_quotes(hot_messages)
        
        # æ‰©å¤§å€™é€‰èŒƒå›´ï¼Œé€‰å–æ›´å¤šæ¶ˆæ¯ä¾› AI ç­›é€‰
        candidates = hot_messages[:30]
        msg_text = "\n".join([
            f"{i+1}. [{m['user']}]: {m['content']}"
            for i, m in enumerate(candidates)
        ])
        
        prompt = f"""ä½ æ˜¯è¿™ä¸ªç¾¤èŠçš„"å¹´åº¦å›å¿†å®˜"ï¼Œæ­£åœ¨ä¸ºç¾¤å‹ä»¬æ•´ç†ä¸€ä»½æœ€çè´µçš„"å¹´åº¦é‡‘å¥é›†"ã€‚

## å€™é€‰æ¶ˆæ¯ï¼š
{msg_text}

## ä»»åŠ¡è¦æ±‚ï¼š
è¯·ä»è¿™äº›æ¶ˆæ¯ä¸­ï¼Œç²¾é€‰å‡º **8-12 æ¡** æœ€å€¼å¾—è¢«è®°ä½çš„è¯è¯­ã€‚

è¿™äº›é‡‘å¥åº”è¯¥è®©ç¾¤å‹ä»¬çœ‹åˆ°æ—¶ï¼š
- å¿ä¸ä½ç¬‘å‡ºå£°
- æˆ–è€…å¿ƒå¤´ä¸€æš–
- æˆ–è€…æ„Ÿå¹"è¯´å¾—çœŸå¥½"
- æˆ–è€…æƒ³èµ·å½“æ—¶çƒ­é—¹çš„åœºæ™¯

### ç±»åˆ«è¯´æ˜ï¼š
- ğŸ˜‚ **ç¬‘åˆ°æµæ³ª**ï¼šè®©å¤§å®¶ç¬‘å‡ºè…¹è‚Œçš„ç¥å¥
- ğŸ’¡ **é†é†çŒé¡¶**ï¼šç¾¤å‹çš„äººç”Ÿæ™ºæ…§
- ğŸ”¥ **ç»å…¸ååœºé¢**ï¼šå¼•å‘å…¨å‘˜æ¥é¾™çš„é«˜å…‰æ—¶åˆ»
- ğŸ’– **å¿ƒé‡Œæš–æš–çš„**ï¼šé‚£äº›è¢«æ¸©æš–åˆ°çš„ç¬é—´
- ğŸ­ **ç¥ä»™å›å¤**ï¼šæ•™ç§‘ä¹¦çº§åˆ«çš„ç¥å›

## è¾“å‡ºæ ¼å¼ï¼ˆJSON æ•°ç»„ï¼‰ï¼š
[
  {{"user": "ç”¨æˆ·å", "content": "å®Œæ•´é‡‘å¥å†…å®¹", "reason": "å…¥é€‰ç†ç”±ï¼ˆ10å­—å†…ï¼Œè¦æ¸©é¦¨æœ‰è¶£ï¼‰", "category": "ç±»åˆ«æ ‡ç­¾"}}
]

## å†™ä½œè¦æ±‚ï¼š
- å…¥é€‰ç†ç”±è¦åƒåœ¨å¤¸å¥–å¥½æœ‹å‹ä¸€æ ·è‡ªç„¶æ¸©æš–
- ä¼˜å…ˆé€‰é‚£äº›èƒ½å”¤èµ·ç¾å¥½å›å¿†çš„è¯
- è®©æ¯ä¸€æ¡é‡‘å¥éƒ½æ‰¿è½½ç€ç¾¤å‹é—´çš„æƒ…è°Š
- é‡‘å¥å†…å®¹ä¿æŒåŸæ ·"""
        
        try:
            content = self._call_api(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ç¾¤å‹ä»¬çš„å¹´åº¦å›å¿†å®˜ï¼Œç”¨æ¸©æš–çš„è§†è§’å‘ç°æ¯ä¸€å¥å€¼å¾—è¢«çè—çš„è¯è¯­ã€‚ä½ ç›¸ä¿¡å¹³å‡¡å¯¹è¯ä¸­è—ç€æœ€çœŸæŒšçš„æƒ…è°Šï¼Œå–„äºå‘ç°é‚£äº›è®©äººä¼šå¿ƒä¸€ç¬‘æˆ–å¿ƒå¤´ä¸€æš–çš„ç¬é—´ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1500
            )
            
            return self._parse_golden_quotes(content, candidates)
            
        except Exception as e:
            logger.warning(f"é‡‘å¥ç”„é€‰å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤")
            return self._mock_golden_quotes(hot_messages)
    
    def _parse_golden_quotes(self, content: str, candidates: list) -> list:
        """è§£æ AI è¿”å›çš„é‡‘å¥ã€‚"""
        import json
        
        try:
            # å°è¯•æå– JSON æ•°ç»„
            import re
            json_match = re.search(r'\[.*\]', content, re.DOTALL)
            if json_match:
                quotes = json.loads(json_match.group())
                return quotes[:5]
        except:
            pass
        
        return self._mock_golden_quotes(candidates)
    
    def _mock_golden_quotes(self, hot_messages: list) -> list:
        """Mock æ¨¡å¼ï¼šè¿”å›æ¨¡æ‹Ÿé‡‘å¥ã€‚"""
        quotes = []
        for msg in hot_messages[:3]:
            quotes.append({
                'user': msg['user'],
                'content': msg['content'][:50],
                'reason': 'å¼•å‘çƒ­çƒˆè®¨è®º'
            })
        return quotes
    
    def summarize_peak_day(self, peak_day_data: dict) -> str:
        """
        ä¸ºå·…å³°æ—¥ç”Ÿæˆ 50 å­—æ‘˜è¦ã€‚
        
        å‚æ•°:
            peak_day_data: {'date': 'æ—¥æœŸ', 'count': æ•°é‡, 'sample_messages': [...]}
            
        è¿”å›:
            50 å­—å·¦å³çš„æ‘˜è¦
        """
        if not peak_day_data or not peak_day_data.get('date'):
            return "è¿™ä¸€å¤©ï¼Œç¾¤é‡Œæ ¼å¤–çƒ­é—¹ï¼Œå¤§å®¶ç•…æ‰€æ¬²è¨€..."
        
        if self.mock_mode:
            return f"é‚£ä¸€å¤©ï¼ˆ{peak_day_data['date']}ï¼‰ï¼Œç¾¤é‡Œå…±äº§ç”Ÿäº† {peak_day_data['count']} æ¡æ¶ˆæ¯ï¼Œå¤§å®¶èŠå¾—æ ¼å¤–å¼€å¿ƒï¼Œè¯é¢˜ä¸€ä¸ªæ¥ä¸€ä¸ªåœä¸ä¸‹æ¥ï¼"
        
        # æ„å»ºæ ·æœ¬æ¶ˆæ¯æ–‡æœ¬
        samples = peak_day_data.get('sample_messages', [])
        msg_text = "\n".join([
            f"- {m['user']}: {m['content'][:30]}"
            for m in samples[:5]
        ])
        
        prompt = f"""è¿™æ˜¯ç¾¤é‡Œæœ€çƒ­é—¹çš„ä¸€å¤©ï¼ˆ{peak_day_data['date']}ï¼Œ{peak_day_data['count']} æ¡æ¶ˆæ¯åˆ·å±ï¼ï¼‰æ˜¯ä»€ä¹ˆè®©å¤§å®¶å¦‚æ­¤çƒ­æƒ…å‘¢ï¼Ÿ

å½“å¤©æ¶ˆæ¯ç‰‡æ®µï¼š
{msg_text}

è¯·ç”¨ 50 å­—å·¦å³ï¼Œåƒåœ¨ç»™è€æœ‹å‹è®²æ•…äº‹ä¸€æ ·ï¼Œæ¸©é¦¨åœ°æè¿°é‚£å¤©çš„çƒ­é—¹åœºæ™¯ã€‚
å¼€å¤´ç”¨"é‚£ä¸€å¤©ï¼Œ"ä½œä¸ºå¼•å­ã€‚
è®©è¯»åˆ°è¿™æ®µè¯çš„äººï¼Œä»¿ä½›èƒ½æ„Ÿå—åˆ°å½“æ—¶ç¾¤é‡Œæ¬¢è…¾çš„æ°”æ°›ã€‚"""
        
        try:
            content = self._call_api(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ç¾¤å‹ä»¬çš„ä¸“å±å›å¿†å®˜ï¼Œç”¨æ•…äº‹çš„æ–¹å¼è®°å½•é‚£äº›çè´µçš„æ—¥å­ã€‚ä½ çš„æ–‡å­—æ€»æ˜¯å¸¦ç€æ¸©åº¦ï¼Œè®©äººè¯»å®Œåå˜´è§’ä¸Šæ‰¬ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=100
            )
            
            return content.strip() if content else self._mock_peak_day_summary(peak_day_data)
            
        except Exception as e:
            logger.warning(f"å·…å³°æ—¥æ‘˜è¦å¤±è´¥: {e}")
            return self._mock_peak_day_summary(peak_day_data)
    
    def _mock_peak_day_summary(self, peak_day_data: dict) -> str:
        """Mock æ¨¡å¼ï¼šè¿”å›é»˜è®¤å·…å³°æ—¥æ‘˜è¦ã€‚"""
        return f"é‚£ä¸€å¤©ï¼ˆ{peak_day_data.get('date', 'æŸå¤©')}ï¼‰ï¼Œç¾¤é‡Œäº§ç”Ÿäº† {peak_day_data.get('count', 0)} æ¡æ¶ˆæ¯ï¼Œæ¬¢å£°ç¬‘è¯­ä¸æ–­ï¼Œå‹è°Šåœ¨è¿™é‡Œå‡æ¸©ï¼"
    
    def generate_topic_memories(self, monthly_data: list) -> list:
        """
        ä¸ºæ¯ä¸ªæœˆç”Ÿæˆè¯é¢˜å›å¿†æè¿°ã€‚
        
        å‚æ•°:
            monthly_data: æœˆåº¦åˆ†ææ•°æ®åˆ—è¡¨ï¼ˆæ¥è‡ª monthly_analyzerï¼‰
            
        è¿”å›:
            [{'month': '1æœˆ', 'topics': [...], 'memory': 'å›å¿†æè¿°'}, ...]
        """
        if not monthly_data:
            return []
        
        results = []
        
        for month_info in monthly_data:
            # è·å–æœ¬æœˆæ ·æœ¬æ¶ˆæ¯
            samples = month_info.get('sample_messages', [])
            old_topics = month_info.get('topics', [])
            
            if self.mock_mode or not samples:
                ai_result = {
                    'topics': [],
                    'memory': self._mock_topic_memory(month_info)
                }
            else:
                ai_result = self._generate_month_memory(month_info, samples, old_topics)
            
            results.append({
                'month': month_info.get('month_name', ''),
                'month_key': month_info.get('month', ''),
                'topics': ai_result.get('topics', []),  # AI æå–çš„å…·ä½“è¯é¢˜
                'memory': ai_result.get('memory', ''),
                'stats': month_info.get('stats', {})
            })
        
        return results
    
    def _generate_month_memory(self, month_info: dict, samples: list, topics: list) -> dict:
        """ä½¿ç”¨ AI ç”Ÿæˆå•æœˆè¯é¢˜å›å¿†å’Œå…·ä½“è¯é¢˜åˆ—è¡¨ã€‚"""
        month_name = month_info.get('month_name', 'æœ¬æœˆ')
        
        # æ„å»ºæ¶ˆæ¯æ ·æœ¬ï¼ˆå¢åŠ æ•°é‡ï¼‰
        msg_text = "\n".join([
            f"- {m['user']}: {m['content'][:60]}"
            for m in samples[:15]
        ])
        
        prompt = f"""è¯·ä¸ºç¾¤èŠçš„ {month_name} å†™ä¸€ä»½æ¸©æš–çš„æœˆåº¦å›å¿†å½•ã€‚

## æœ¬æœˆæ¶ˆæ¯æ ·æœ¬ï¼š
{msg_text}

## ä»»åŠ¡ï¼š
1. æå– 3-5 ä¸ªæœ¬æœˆ**å…·ä½“å‘ç”Ÿçš„æ¸©é¦¨æ•…äº‹/è¯é¢˜**ï¼ˆæ˜¯èƒ½è®©ç¾¤å‹ä»¬å›å¿†èµ·æ¥çš„äº‹æƒ…ï¼‰
2. å†™ä¸€æ®µ 80-100 å­—çš„æœˆåº¦å›å¿†ï¼Œåƒæ˜¯åœ¨ç»™è€æœ‹å‹å¯„å»çš„æ˜ä¿¡ç‰‡

## å†™ä½œæŒ‡å¼•ï¼š
- ç”¨"è¿™ä¸ªæœˆ"å¼€å¤´ï¼Œåƒè®²æ•…äº‹ä¸€æ ·å¨“å¨“é“æ¥
- è®©ç¾¤å‹è¯»åˆ°æ—¶èƒ½æƒ³èµ·é‚£äº›å¿«ä¹æ—¶å…‰
- æ–‡å­—è¦æ¸©æš–ï¼Œåƒå†¬æ—¥é‡Œçš„çƒ­å¯å¯

## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼JSONï¼‰ï¼š
{{
  "topics": [
    {{"title": "è¯é¢˜æ ‡é¢˜ï¼ˆ4-8å­—ï¼Œè¦æœ‰æ•…äº‹æ„Ÿï¼‰", "desc": "ä¸€å¥è¯æè¿°ï¼Œæ¸©é¦¨æœ‰è¶£"}},
    ...
  ],
  "memory": "è¿™ä¸ªæœˆï¼Œ..."
}}

## ç¤ºä¾‹ï¼š
{{
  "topics": [
    {{"title": "å°æ˜çš„æƒŠå–œç”Ÿæ—¥", "desc": "å‡Œæ™¨å‡†æ—¶é€ä¸Šç¥ç¦ï¼Œæš–åˆ°å¿ƒå"}},
    {{"title": "æ‰“å·¥äººäº’åŠ©è”ç›Ÿ", "desc": "åŠ ç­åæ§½é‡Œè—ç€äº’ç›¸æ‰“æ°”"}},
    {{"title": "è·¨å¹´çº¦å®š", "desc": "æœŸå¾…ç€ä¸€èµ·è¿æ¥æ–°å¹´"}}
  ],
  "memory": "è¿™ä¸ªæœˆï¼Œç¾¤é‡Œå……æ»¡äº†æ¸©é¦¨çš„æƒŠå–œâ€”â€”å¤§å®¶ä¸€èµ·ç»™å°æ˜åº†ç”Ÿï¼Œè™½ç„¶éš”ç€å±å¹•ï¼Œç¥ç¦å´æš–æš–çš„..."
}}

## è¦æ±‚ï¼š
- è¯é¢˜è¦**å…·ä½“ä¸”æ¸©æš–**ï¼Œèƒ½å”¤èµ·ç¾å¥½å›å¿†
- æè¿°è¦**æœ‰æ¸©åº¦**ï¼Œè®©äººè¯»äº†å˜´è§’ä¸Šæ‰¬
- é¿å…æ•æ„Ÿè¯é¢˜ï¼Œç”¨æ­£å‘æ–¹å¼æè¿°"""
        
        try:
            content = self._call_api(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ç”¨å¿ƒè®°å½•å‹æƒ…æ•…äº‹çš„å›å¿†å®˜ï¼Œæ“…é•¿ä»æ—¥å¸¸å¯¹è¯ä¸­å‘ç°é‚£äº›é—ªé—ªå‘å…‰çš„æ¸©é¦¨æ—¶åˆ»ã€‚åªè¾“å‡ºJSONæ ¼å¼ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            # è§£æ JSON
            import json
            import re
            
            # å°è¯•æå– JSON
            json_match = re.search(r'\{[\s\S]*\}', content)
            if json_match:
                result = json.loads(json_match.group())
                return {
                    'topics': result.get('topics', []),
                    'memory': result.get('memory', self._mock_topic_memory(month_info))
                }
            else:
                return {
                    'topics': [],
                    'memory': content.strip() if content else self._mock_topic_memory(month_info)
                }
            
        except Exception as e:
            logger.warning(f"{month_name}è¯é¢˜æå–å¤±è´¥: {e}")
            return {
                'topics': [],
                'memory': self._mock_topic_memory(month_info)
            }
    
    def analyze_weekly_batches(self, weekly_samples: list, use_cache: bool = True) -> tuple[str, dict]:
        """
        æŒ‰å‘¨æ‰¹æ¬¡åˆ†ææ¶ˆæ¯ï¼Œç”Ÿæˆå¹´åº¦æ·±åº¦æ€»ç»“ã€‚
        
        å‚æ•°:
            weekly_samples: æ¯å‘¨æ¶ˆæ¯æ ·æœ¬åˆ—è¡¨ [{'week': '...', 'messages': [...]}, ...]
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼ˆé»˜è®¤å¼€å¯ï¼‰
            
        è¿”å›:
            (å¹´åº¦æ€»ç»“æ–‡æœ¬, æ¯å‘¨æ€»ç»“å­—å…¸ {'2024-W01': 'æ€»ç»“å†…å®¹...'})
        """
        if not weekly_samples:
            return "", {}
        
        if self.mock_mode:
            return "ï¼ˆMockæ¨¡å¼è·³è¿‡æ·±åº¦å‘¨åº¦åˆ†æï¼‰", {}
        
        # === ç¼“å­˜å¤„ç† ===
        import hashlib
        import json
        from pathlib import Path
        
        # ç¼“å­˜æ”¾åœ¨é¡¹ç›®çš„ tmp ç›®å½•
        cache_dir = Path(__file__).parent.parent / "tmp"
        cache_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¡ç®—æ•°æ®å“ˆå¸Œï¼ˆç”¨äºåˆ¤æ–­æ•°æ®æ˜¯å¦å˜åŒ–ï¼‰
        cache_key_data = json.dumps([
            {'week': w['week'], 'count': len(w['messages']), 
             'sample': w['messages'][0]['content'][:50] if w['messages'] else ''}
            for w in weekly_samples
        ], ensure_ascii=False, sort_keys=True)
        cache_hash = hashlib.md5(cache_key_data.encode()).hexdigest()[:12]
        cache_file = cache_dir / f"weekly_analysis_{cache_hash}.json"
        
        # å°è¯•è¯»å–ç¼“å­˜
        if use_cache and cache_file.exists():
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cached = json.load(f)
                    print(f"   ğŸ’¾ å·²åŠ è½½å‘¨åº¦åˆ†æç¼“å­˜ ({len(cached.get('weekly_summaries', {}))} å‘¨)")
                    return cached.get('yearly_summary', ''), cached.get('weekly_summaries', {})
            except Exception as e:
                logger.warning(f"ç¼“å­˜è¯»å–å¤±è´¥: {e}")
        
        print(f"   ğŸ§  æ­£åœ¨è¿›è¡Œæ·±åº¦å‘¨åº¦åˆ†æ (å…± {len(weekly_samples)} å‘¨)...")
        
        weekly_summaries_dict = {}
        weekly_summaries_text_list = []
        
        # å°è¯•ä½¿ç”¨ tqdm è¿›åº¦æ¡
        try:
            from tqdm import tqdm
            week_iter = tqdm(weekly_samples, desc="   å‘¨åº¦åˆ†æ", unit="å‘¨", ncols=60)
        except ImportError:
            week_iter = weekly_samples
        
        # æ¯å‘¨å•ç‹¬åˆ†æ (å¸¦è·¨å‘¨ä¸Šä¸‹æ–‡)
        previous_summary = ""  # ç”¨äºè¿è´¯å‰§æƒ…
        for i, week_data in enumerate(week_iter):
            week_label = week_data['week']
            msgs = week_data['messages']
            if not msgs:
                continue
                
            # æ„å»ºæ¶ˆæ¯æ–‡æœ¬ (åªå– user: content) - æ‰©å¤§åˆ° 15000 å­—ç¬¦
            msg_text = "\n".join([f"{m['user']}: {m['content']}" for m in msgs])
            
            # æ„å»ºè·¨å‘¨ä¸Šä¸‹æ–‡
            context_section = ""
            if previous_summary:
                context_section = f"""
## ä¸Šå‘¨å›é¡¾ï¼ˆç”¨äºå‰§æƒ…è¿è´¯ï¼‰ï¼š
{previous_summary[:500]}
---
"""
            
            prompt = f"""ä½ æ˜¯ç¾¤å‹ä»¬çš„å¹´åº¦å›å¿†å®˜ï¼Œæ­£åœ¨ä¸ºå¤§å®¶æ’°å†™ä¸€ä»½èƒ½å‹¾èµ·ç¾å¥½å›å¿†çš„å‘¨æŠ¥ã€‚

{context_section}## {week_label} æœ¬å‘¨æ¶ˆæ¯è®°å½•ï¼š
{msg_text[:15000]}

## å†™ä½œä»»åŠ¡ï¼š
è¯·ç”¨æ¸©æš–ã€æ€€æ—§çš„ç¬”è§¦ï¼Œæ€»ç»“è¿™å‘¨ç¾¤é‡Œçš„æ¸©é¦¨ç¬é—´å’Œæœ‰è¶£æ•…äº‹ã€‚

## å†™ä½œè¦æ±‚ï¼š
1. **å…·ä½“äº‹ä»¶**ï¼šåˆ—å‡º 2-3 ä¸ªè®©äººå°è±¡æ·±åˆ»çš„è¯é¢˜æˆ–æ•…äº‹ï¼Œè¦æœ‰ç»†èŠ‚ï¼ˆè°è¯´äº†ä»€ä¹ˆã€å‘ç”Ÿäº†ä»€ä¹ˆï¼‰
2. **é‡‘å¥æå–**ï¼šæŒ‘é€‰ 1-2 ä¸ªè®©äººä¼šå¿ƒä¸€ç¬‘çš„æ¢—æˆ–é‡‘å¥
3. **å‰§æƒ…è¿è´¯**ï¼šå¦‚æœæœ‰ä¸Šå‘¨å»¶ç»­çš„è¯é¢˜ï¼Œè‡ªç„¶åœ°ä¸²è”èµ·æ¥
4. **æ–‡é£è¦æ±‚**ï¼š
   - åƒè€æœ‹å‹åœ¨å›å¿†å¾€äº‹ï¼Œå¨“å¨“é“æ¥
   - è®©ç¾¤å‹è¯»åˆ°æ—¶èƒ½æƒ³èµ·å½“æ—¶çš„æƒ…æ™¯
   - è¯­æ°”æ¸©æš–å¹½é»˜ï¼Œè®©äººè¯»å®Œå˜´è§’ä¸Šæ‰¬

## â›” ç¦æ­¢äº‹é¡¹ï¼š
- ä¸¥ç¦æåŠåˆ†æ‰‹ã€ç¦»å©šã€å†²çªã€åµæ¶ã€æŠ±æ€¨ç­‰è´Ÿé¢è¯é¢˜
- å¦‚æœæ¶ˆæ¯ä¸­æœ‰è´Ÿé¢å†…å®¹ï¼Œè¯·å¿½ç•¥æˆ–è½¬åŒ–ä¸ºè½»æ¾çš„åæ§½é£æ ¼
- ä¿æŒæ•´ä½“ç§¯æã€æ¸©é¦¨çš„åŸºè°ƒ"""

            try:
                summary = self._call_api(
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ¸©æš–çš„å›å¿†å½•ä½œå®¶ï¼Œæ“…é•¿ä»æ—¥å¸¸å¯¹è¯ä¸­å‘ç°é—ªå…‰æ—¶åˆ»ï¼Œç”¨å……æ»¡æ•…äº‹æ„Ÿçš„æ–‡å­—è®©è¯»è€…é‡æ¸©ç¾å¥½ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.6,
                    max_tokens=500
                )
                weekly_summaries_dict[week_label] = summary
                weekly_summaries_text_list.append(f"### {week_label}\n{summary}")
                previous_summary = summary  # æ›´æ–°è·¨å‘¨ä¸Šä¸‹æ–‡
                print(f"     âœ“ {week_label} åˆ†æå®Œæˆ")
            except Exception as e:
                logger.warning(f"{week_label} åˆ†æå¤±è´¥: {e}")
        
        # æ±‡æ€»æ‰€æœ‰å‘¨æŠ¥ç”Ÿæˆå¹´åº¦æ€»ç»“
        all_summaries = "\n\n".join(weekly_summaries_text_list)
        
        final_prompt = f"""è¿™ä¸€å¹´ï¼Œæˆ‘ä»¬åœ¨ç¾¤é‡Œç•™ä¸‹äº†æ— æ•°æ¸©æš–çš„å›å¿†ã€‚ç°åœ¨ï¼Œè¯·ä¸ºå¤§å®¶å†™ä¸€ä»½è®©äººæƒ³æ¬å‡ºå°æ¿å‡³ç»†ç»†å“è¯»çš„å¹´åº¦å›å¿†å½•ã€‚

## æ¯å‘¨æ‘˜è¦ï¼ˆæ»¡æ»¡çš„å›å¿†ï¼‰ï¼š
{all_summaries}

## ä»»åŠ¡ï¼š
è¯·ç”Ÿæˆä¸€ç¯‡è®©äººè¯»å®Œä¼šå¿ƒå¤´ä¸€æš–çš„å¹´åº¦å›å¿†æ–‡ç« ï¼ˆMarkdownæ ¼å¼ï¼‰ï¼š

### ğŸ¬ å¦‚æœè¿™ä¸€å¹´æ˜¯ä¸€éƒ¨ç”µå½±
ç»™å®ƒèµ·ä¸ªæ¸©æš–çš„åå­—ï¼Œå†™ä¸€æ®µè®©äººå……æ»¡æœŸå¾…çš„"å‰§æƒ…ç®€ä»‹"ï¼ˆ50å­—å·¦å³ï¼‰ã€‚

### ğŸŒŸ å¹´åº¦é«˜å…‰æ—¶åˆ»
åˆ—å‡º 5 ä¸ªæœ€å€¼å¾—çºªå¿µçš„æ¸©é¦¨åœºæ™¯æˆ–æ¬¢ä¹äº‹ä»¶ï¼š
- è¦ç»“åˆå…·ä½“å‘¨çš„å†…å®¹ç»†èŠ‚
- è®©ç¾¤å‹ä»¬èƒ½ç¬¬ä¸€æ—¶é—´æƒ³èµ·å½“æ—¶çš„å¿«ä¹
- ç”¨ç”»é¢æ„Ÿå¼ºçš„è¯­è¨€æè¿°

### ğŸ“œ å‹è°Šç¼–å¹´å²
ç”¨æ—¶é—´çº¿ä¸²èµ·è¿™ä¸€å¹´çš„æ•…äº‹ï¼š
- åƒç»™æœªæ¥çš„è‡ªå·±å†™ä¿¡ä¸€æ ·
- è®°å½•å¤§å®¶çš„å˜åŒ–å’Œæˆé•¿
- çªå‡ºé‚£äº›"åªæœ‰æˆ‘ä»¬æ‡‚"çš„ç¬é—´

### ğŸ’¬ æˆ‘ä»¬çš„ä¸“å±è®°å¿†
é‚£äº›åªæœ‰æˆ‘ä»¬æ‰æ‡‚çš„æ¢—å’Œå£å¤´ç¦…ï¼š
- æ˜¯è¿™ä¸€å¹´å‹è°Šçš„å°è®°
- è®©æ¯ä¸ªè¯»åˆ°çš„äººä¼šå¿ƒä¸€ç¬‘

## å†™ä½œé£æ ¼è¦æ±‚ï¼š
1. **å‹¾èµ·å›å¿†**ï¼šåƒè€æœ‹å‹ç¿»ç€ç›¸å†ŒèŠå¾€äº‹ï¼Œæ¯ä¸ªç»†èŠ‚éƒ½èƒ½è®©äººæƒ³èµ·å½“æ—¶çš„æƒ…æ™¯
2. **æ¸©æƒ…è„‰è„‰**ï¼šå­—é‡Œè¡Œé—´éƒ½æ˜¯å¯¹ç¾¤å‹çš„çè§†ï¼Œè®©è¯»è€…æ„Ÿå—åˆ°"æˆ‘ä»¬æ˜¯ä¸€ä¼™çš„"
3. **å¹½é»˜æš–å¿ƒ**ï¼šå¹½é»˜ä¸­å¸¦ç€æš–æ„ï¼Œè®©äººç¬‘ç€ç¬‘ç€å°±è§‰å¾—å¾ˆå¹¸ç¦
4. **ç»†èŠ‚ä¸ºç‹**ï¼šå¼•ç”¨å…·ä½“çš„äººåã€äº‹ä»¶ã€é‡‘å¥ï¼Œè®©ç¾¤å‹èƒ½ç¬¬ä¸€æ—¶é—´å¯¹å·å…¥åº§

## â›” ç¦æ­¢äº‹é¡¹ï¼š
- ä¸¥ç¦æåŠåˆ†æ‰‹ã€ç¦»å©šã€å†²çªã€åµæ¶ã€æŠ±æ€¨ç­‰è´Ÿé¢è¯é¢˜
- ä¿æŒæ•´ä½“ç§¯æã€æ¸©é¦¨ã€æ€€æ—§çš„åŸºè°ƒ"""

        try:
            print("   ğŸ“ æ­£åœ¨ç”Ÿæˆå¹´åº¦æ·±åº¦æ€»ç»“...")
            content = self._call_api(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ–‡ç¬”ç»†è…»çš„å›å¿†å½•ä½œå®¶ï¼Œæ“…é•¿ç”¨æ¸©æš–æ€€æ—§çš„ç¬”è§¦æŠŠå¹³å‡¡æ—¥å¸¸å†™æˆè®©äººåŠ¨å®¹çš„æ•…äº‹ã€‚ä½ çš„æ–‡å­—èƒ½å‹¾èµ·è¯»è€…å¿ƒåº•æœ€æŸ”è½¯çš„å›å¿†ã€‚"},
                    {"role": "user", "content": final_prompt}
                ],
                temperature=0.75,
                max_tokens=2500
            )
            
            # ä¿å­˜ç¼“å­˜
            if use_cache:
                try:
                    with open(cache_file, 'w', encoding='utf-8') as f:
                        json.dump({
                            'yearly_summary': content,
                            'weekly_summaries': weekly_summaries_dict
                        }, f, ensure_ascii=False, indent=2)
                    print(f"   ğŸ’¾ å‘¨åº¦åˆ†æå·²ç¼“å­˜")
                except Exception as e:
                    logger.warning(f"ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
            
            return content, weekly_summaries_dict
        except Exception as e:
            logger.warning(f"å¹´åº¦æ€»ç»“ç”Ÿæˆå¤±è´¥: {e}")
            return "å¹´åº¦æ€»ç»“ç”Ÿæˆå¤±è´¥", weekly_summaries_dict

    def generate_monthly_summary_from_weekly(
        self, 
        monthly_data: list, 
        weekly_summaries: dict
    ) -> list:
        """
        åŸºäºå‘¨åº¦æ€»ç»“ç”Ÿæˆæœˆåº¦è¯é¢˜å›å¿†ï¼ˆæ›´ç²¾å‡†ï¼‰ã€‚
        """
        results = []
        import datetime
        
        for month_info in monthly_data:
            month_key = month_info.get('month', '') # 'YYYY-MM'
            month_name = month_info.get('month_name', '')
            
            # æ‰¾åˆ°å±äºè¯¥æœˆçš„æ‰€æœ‰å‘¨æ€»ç»“
            relevant_weeks = []
            for week_key, summary in weekly_summaries.items():
                try:
                    # ç®€å•åˆ¤æ–­ï¼šå¦‚æœå‘¨çš„å­—ç¬¦ä¸²é‡ŒåŒ…å«å¹´æœˆ... å…¼å®¹ YYYY-MM
                    # æˆ–è€…è§£æ ISO å‘¨
                    if month_key in week_key:
                         relevant_weeks.append(summary)
                    else:
                        # å°è¯•é€šè¿‡æ—¥æœŸè®¡ç®—
                        y, w = week_key.split('-W')
                        week_start = datetime.datetime.strptime(f'{y}-W{w}-1', "%Y-W%W-%w")
                        if week_start.strftime('%Y-%m') == month_key:
                            relevant_weeks.append(summary)
                except:
                    pass
            
            if not relevant_weeks:
                # å°è¯•æ™®é€šç”Ÿæˆæˆ–Mock
                if self.mock_mode:
                    memory = self._mock_topic_memory(month_info)
                    topics = []
                else:
                    # å¦‚æœæ²¡æœ‰å‘¨æ•°æ®ï¼Œè¿˜æ˜¯è°ƒç”¨åŸæ¥çš„æ–¹æ³•ï¼Œæˆ–è€…è¿”å›ç©º
                    # è¿™é‡Œä¸ºäº†å¥å£®æ€§ï¼Œè°ƒç”¨åŸæ¥çš„é‡‡æ ·æ–¹æ³•
                    samples = month_info.get('sample_messages', [])
                    if samples:
                        res = self._generate_month_memory(month_info, samples, [])
                        memory = res.get('memory', '')
                        topics = res.get('topics', [])
                    else:
                        memory = self._mock_topic_memory(month_info)
                        topics = []
            else:
                # ä½¿ç”¨å‘¨æŠ¥æ±‡æ€»ç”ŸæˆæœˆæŠ¥
                combined_weekly = "\n".join(relevant_weeks)
                prompt = f"""ä»¥ä¸‹æ˜¯ {month_name} é‡Œé‚£äº›å€¼å¾—çè—çš„ç¾¤èŠæ—¶å…‰ï¼š
{combined_weekly}

è¯·åŸºäºè¿™äº›å›å¿†ï¼Œå†™ä¸€æ®µ 80-100 å­—çš„**æœˆåº¦æ¸©é¦¨å›å¿†**ã€‚
åŒæ—¶æå– 3 ä¸ªæœ€èƒ½è§¦åŠ¨äººå¿ƒçš„è¯é¢˜æ ‡ç­¾ã€‚

å†™ä½œæŒ‡å—ï¼š
- ç”¨"è¿™ä¸ªæœˆ"å¼€å¤´ï¼Œè®©å…¨æ–‡åƒæ˜¯åœ¨ç»™è€æœ‹å‹å†™ä¿¡
- è®©ç¾¤å‹è¯»åˆ°æ—¶èƒ½æƒ³èµ·é‚£äº›å¿«ä¹æ—¶å…‰
- æ–‡å­—è¦æ¸©æš–ï¼Œåƒå†¬æ—¥é‡Œçš„ä¸€æ¯çƒ­èŒ¶

è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
  "topics": [{{"title": "...", "desc": "..."}}],
  "memory": "..."
}}"""
                try:
                    response = self.client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç²¾ç‚¼çš„ç¾¤èŠè®°å½•å‘˜ã€‚è¾“å‡ºJSONã€‚"},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.7
                    )
                    content = self._extract_content(response)
                    import json, re
                    json_match = re.search(r'\{[\s\S]*\}', content)
                    if json_match:
                        res = json.loads(json_match.group())
                        memory = res.get('memory', '')
                        topics = res.get('topics', [])
                    else:
                        memory = content
                        topics = []
                except Exception as e:
                    print(f"   âš ï¸ {month_name} æ±‡æ€»å¤±è´¥: {e}")
                    memory = self._mock_topic_memory(month_info)
                    topics = []

            results.append({
                'month': month_name,
                'month_key': month_key,
                'topics': topics,
                'memory': memory,
                'stats': month_info.get('stats', {})
            })
            
        return results

    def generate_user_profiles_with_mbti(self, df: pd.DataFrame, top_users: List[str]) -> List[dict]:
        """
        ç”Ÿæˆç”¨æˆ·ç”»åƒåŠ MBTI é¢„æµ‹ã€‚
        
        å‚æ•°:
            df: å®Œæ•´æ¶ˆæ¯ DataFrame
            top_users: éœ€è¦åˆ†æçš„ç”¨æˆ·åˆ—è¡¨ (ç”¨æˆ·å)
            
        è¿”å›:
            [{'user': '...', 'persona': '...', 'description': '...', 'mbti': '...'}, ...]
        """
        profiles = []
        if self.mock_mode:
            return self._mock_user_profiles_mbti(top_users)
        
        print(f"   ğŸ‘¥ æ­£åœ¨ç”Ÿæˆç”¨æˆ·ç”»åƒåŠ MBTI (åˆ†æå‰ {len(top_users)} ä½æ´»è·ƒç”¨æˆ·)...")
        
        # å°è¯•ä½¿ç”¨ tqdm è¿›åº¦æ¡
        try:
            from tqdm import tqdm
            user_iter = tqdm(top_users, desc="   ç”¨æˆ·ç”»åƒ", unit="äºº", ncols=60)
        except ImportError:
            user_iter = top_users
        
        for user in user_iter:
            # æå–è¯¥ç”¨æˆ·çš„å‘è¨€æ ·æœ¬ - æ‰©å¤§åˆ° 1000 æ¡ä»¥è·å¾—æ›´å‡†ç¡®çš„ç”»åƒ
            user_df = df[df['user'] == user]
            sample_size = min(1000, len(user_df))
            user_msgs = user_df['content'].sample(n=sample_size).tolist()
            msg_text = "\n".join(user_msgs)[:15000]  # æˆªæ–­ä»¥æ§åˆ¶ token
            
            prompt = f"""è¯·ä¸ºè¿™ä½ç¾¤å‹å†™ä¸€ä»½æ¸©æš–çš„äººç‰©ç”»åƒï¼Œè®© TA æ„Ÿå—åˆ°è¢«çœ‹è§å’Œè¢«å–œçˆ±ã€‚

## ç”¨æˆ·å‘è¨€æ ·æœ¬ï¼š
{msg_text}

## ä»»åŠ¡ï¼š
1. **æ¸©æš–æ ‡ç­¾**ï¼šç»™ TA ä¸€ä¸ªå……æ»¡å–œçˆ±çš„ç§°å·ï¼ˆå¦‚ï¼šæ·±å¤œæš–å¿ƒå°ç²¾çµã€ç¾¤é‡Œçš„å°å¤ªé˜³ã€æ°¸è¿œåœ¨çº¿çš„æ¸©æŸ”ï¼‰ï¼Œ4-6å­—ã€‚
2. **ç”»åƒæè¿°**ï¼šç”¨æ¸©æš–çš„ä¸€å¥è¯æè¿° TA åœ¨ç¾¤é‡Œçš„æ ·å­ï¼Œåƒæ˜¯åœ¨å‘æœ‹å‹ä»‹ç»è¿™ä¸ªå¾ˆç‰¹åˆ«çš„äººã€‚
3. **MBTI çŒœæƒ³**ï¼šæ ¹æ®å‘è¨€é£æ ¼çŒœæµ‹ TA çš„ MBTI äººæ ¼ï¼ˆå¦‚ ENFPï¼‰ï¼Œå¹¶ç”¨æ‹¬å·ç®€è¿°ä¸ºä»€ä¹ˆï¼Œè¯­æ°”è¦å……æ»¡æ¬£èµã€‚

## å†™ä½œæŒ‡å—ï¼š
- æƒ³è±¡ä½ åœ¨å‘æ–°æœ‹å‹ä»‹ç»"æˆ‘ä»¬ç¾¤é‡Œçš„å®è—æœ‹å‹"
- è®© TA è¯»åˆ°æ—¶ä¼šå¿ƒä¸€ç¬‘ï¼Œæ„Ÿå—åˆ°è¢«çè§†
- å‘ç° TA çš„é—ªå…‰ç‚¹ï¼Œç”¨æ¸©æš–çš„æ–¹å¼è¡¨è¾¾

## è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
  "persona": "...",
  "description": "...",
  "mbti": "..."
}}"""

            try:
                content = self._call_api(
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å……æ»¡æ¬£èµçš„äººç‰©ç”»åƒå¸ˆï¼Œæ“…é•¿å‘ç°æ¯ä¸ªäººçš„é—ªå…‰ç‚¹ï¼Œç”¨æ¸©æš–çš„æ–‡å­—è®©æ¯ä¸ªäººéƒ½æ„Ÿå—åˆ°è¢«çœ‹è§çš„å–œæ‚¦ã€‚åªè¾“å‡ºJSONã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,
                    max_tokens=200
                )
                
                # è§£æ JSON
                import json
                import re
                json_match = re.search(r'\{[\s\S]*\}', content)
                if json_match:
                    res = json.loads(json_match.group())
                    profiles.append({
                        'user': user,
                        'persona': res.get('persona', 'ç¥ç§˜ç¾¤å‹'),
                        'description': res.get('description', 'æš‚æ— æè¿°'),
                        'mbti': res.get('mbti', 'UNKNOWN')
                    })
                else:
                     profiles.append({'user': user, 'persona': 'ç¥ç§˜ç¾¤å‹', 'description': content[:20], 'mbti': 'UNKNOWN'})
                     
            except Exception as e:
                logger.warning(f"åˆ†æç”¨æˆ· {user} å¤±è´¥: {e}")
                profiles.append({'user': user, 'persona': 'ä½è°ƒè·¯äºº', 'description': 'ä¿æŒç¥ç§˜', 'mbti': 'ISTJ'})
        
        return profiles

    def _mock_user_profiles_mbti(self, users: List[str]) -> List[dict]:
        """Mock ç”¨æˆ·ç”»åƒæ•°æ®"""
        roles = [
            # åˆ†æå¸ˆå‹ (NT)
            ('ç¾¤é‡Œçš„æ™ºå›Šå›¢', 'INTJ', 'æ€»èƒ½ç»™å‡ºæ·±æ€ç†Ÿè™‘çš„å»ºè®®'),
            ('å¥½å¥‡å®å®', 'INTP', 'å¯¹ä¸€åˆ‡æ–°é²œäº‹ç‰©å……æ»¡æ¢ç´¢æ¬²'),
            ('ç‚¹å­å¤§ç‹', 'ENTP', 'è„‘æ´å¤§å¼€ï¼Œåˆ›æ„æ— é™'),
            ('å¤©ç”Ÿé¢†èˆªè€…', 'ENTJ', 'å¸¦å¤§å®¶ä¸€èµ·å†²ï¼Œä»ä¸æ‰é˜Ÿ'),
            # å¤–äº¤å®˜å‹ (NF)
            ('æ·±å¤œæš–å¿ƒå°ç²¾çµ', 'INFJ', 'æ€»åœ¨æœ€éœ€è¦çš„æ—¶å€™å‡ºç°'),
            ('æ¸©æŸ”çš„ç†æƒ³å®¶', 'INFP', 'ç”¨æ–‡å­—ä¼ é€’æ¸©æš–å’Œå¸Œæœ›'),
            ('ç¾¤é‡Œçš„å°å¤ªé˜³', 'ENFP', 'éšæ—¶éƒ½èƒ½ç‚¹äº®å¤§å®¶çš„ä¸€å¤©'),
            ('æš–åœºæ‹…å½“', 'ENFJ', 'è®©æ¯ä¸ªäººéƒ½æ„Ÿåˆ°è¢«æ¬¢è¿'),
            # å®ˆæŠ¤è€…å‹ (SJ)
            ('é»˜é»˜å®ˆæŠ¤è€…', 'ISTJ', 'é è°±å¾—è®©äººå®‰å¿ƒ'),
            ('æ¸©æŸ”å®ˆæŠ¤è€…', 'ISFJ', 'æ‚„æ‚„å…³å¿ƒç€æ¯ä¸€ä¸ªäºº'),
            ('ç§©åºç»´æŠ¤å‘˜', 'ESTJ', 'ç¾¤é‡Œæœ‰äº‹ï¼Œç¬¬ä¸€ä¸ªç«™å‡ºæ¥'),
            ('çƒ­å¿ƒå¤§ä½¿', 'ESFJ', 'æ€»åœ¨å¼ ç½—èšä¼šå’Œæ´»åŠ¨'),
            # æ¢é™©å®¶å‹ (SP)
            ('ç¥ç§˜å†·é…·ä¾ ', 'ISTP', 'è¯ä¸å¤šä½†å¥å¥åœ¨ç‚¹ä¸Š'),
            ('æµªæ¼«ç”Ÿæ´»å®¶', 'ISFP', 'æŠŠæ—¥å¸¸è¿‡æˆè¯—'),
            ('å¿«ä¹åˆ¶é€ æœº', 'ESTP', 'æœ‰ TA çš„åœ°æ–¹å°±æœ‰ç¬‘å£°'),
            ('æ°”æ°›æ‹…å½“', 'ESFP', 'ç¾¤é‡Œçš„å¼€å¿ƒæœï¼Œæ°¸è¿œæ´»åŠ›æ»¡æ»¡'),
        ]
        import random
        results = []
        for i, user in enumerate(users):
            role = roles[i % len(roles)]
            results.append({
                'user': user,
                'persona': role[0],
                'description': f"æˆ‘ä»¬ç¾¤é‡Œçš„{role[0]}ï¼Œ{role[2]}ï¼Œæœ‰ TA çš„åœ°æ–¹å°±å……æ»¡æ¸©æš–",
                'mbti': role[1]
            })
        return results

    def _mock_topic_memory(self, month_info: dict) -> str:
        """Mock æ¨¡å¼ï¼šè¿”å›é»˜è®¤è¯é¢˜å›å¿†ã€‚"""
        month_name = month_info.get('month_name', 'è¿™ä¸ªæœˆ')
        stats = month_info.get('stats', {})
        count = stats.get('total_messages', 0)
        
        templates = [
            f"è¿™ä¸ªæœˆï¼Œç¾¤é‡Œçš„ {count} æ¡æ¶ˆæ¯é‡Œï¼Œè—ç€æ— æ•°ä¸ªè®©äººä¼šå¿ƒä¸€ç¬‘çš„ç¬é—´â€”â€”æœ‰äººåœ¨å‘æ›´æ—©é—®å€™ï¼Œæœ‰äººåœ¨æ·±å¤œé™ªèŠï¼Œè¿™å°±æ˜¯æˆ‘ä»¬çš„æ—¥å¸¸ï¼Œå¹³å‡¡å´æ¸©æš–ã€‚",
            f"è¿™ä¸ªæœˆï¼Œæˆ‘ä»¬ç”¨ {count} æ¡æ¶ˆæ¯è®°å½•ç€å½¼æ­¤çš„ç”Ÿæ´»ã€‚è™½ç„¶éš”ç€å±å¹•ï¼Œä½†å‹æƒ…çš„æ¸©åº¦ä¸€ç›´åœ¨çº¿ï¼Œä»æœªç¼ºå¸­ã€‚",
            f"è¿™ä¸ªæœˆï¼Œ{count} æ¡æ¶ˆæ¯ä¸²èµ·äº†æ— æ•°ä¸ªæ¸©é¦¨æ—¶åˆ»â€”â€”ä¸€èµ·åæ§½ã€ä¸€èµ·å¤§ç¬‘ã€ä¸€èµ·åŠ æ²¹æ‰“æ°”ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬ã€‚",
        ]
        import random
        return random.choice(templates)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    import sys
    from data_loader import load_chat_data
    from stats_engine import calculate_stats
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python ai_analyzer.py <json_file_path>")
        print("\næ³¨æ„: éœ€è¦é…ç½® .env æ–‡ä»¶ä¸­çš„ LLM_API_KEY")
        print("å¦‚æœæ²¡æœ‰é…ç½®ï¼Œå°†ä½¿ç”¨ Mock æ¨¡å¼è¿”å›æ¨¡æ‹Ÿæ•°æ®")
        sys.exit(1)
    
    file_path = sys.argv[1]
    
    try:
        df, session = load_chat_data(file_path)
        stats = calculate_stats(df)
        
        analyzer = AIAnalyzer()
        print(f"Mock æ¨¡å¼: {analyzer.mock_mode}")
        
        result = analyzer.analyze(df, stats['top_users'])
        
        print("\n=== AI åˆ†æç»“æœ ===")
        print(result['raw_content'])
        
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
