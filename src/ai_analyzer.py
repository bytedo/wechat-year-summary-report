"""
ai_analyzer.py - AI åˆ†æä»£ç†æ¨¡å—

ä½¿ç”¨ LLM å¯¹èŠå¤©æ•°æ®è¿›è¡Œæ·±åº¦åˆ†æï¼ŒåŒ…æ‹¬è¯é¢˜æ€»ç»“ã€ç”¨æˆ·ç”»åƒç­‰ã€‚
æ”¯æŒ Mock æ¨¡å¼ï¼Œå½“æ²¡æœ‰ API Key æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®ã€‚
"""

import os
import random
import re
from typing import List, Optional

import pandas as pd
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class AIAnalyzer:
    """
    AI åˆ†æå™¨ï¼Œæ”¯æŒ OpenAI å…¼å®¹æ¥å£ï¼ˆDeepSeek/Moonshot ç­‰ï¼‰ã€‚
    """
    
    def __init__(self, base_url: str = None, api_key: str = None, model: str = None):
        """
        åˆå§‹åŒ– AI åˆ†æå™¨ã€‚
        
        å‚æ•°:
            base_url: API åŸºç¡€åœ°å€
            api_key: API å¯†é’¥
            model: æ¨¡å‹åç§°
        """
        self.base_url = base_url or os.getenv('LLM_BASE_URL', 'https://api.deepseek.com/v1')
        self.api_key = api_key or os.getenv('LLM_API_KEY', '')
        self.model = model or os.getenv('LLM_MODEL', 'deepseek-chat')
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨ Mock æ¨¡å¼
        self.mock_mode = not self.api_key or self.api_key == 'your-api-key-here'
        
        if not self.mock_mode:
            try:
                from openai import OpenAI
                self.client = OpenAI(
                    base_url=self.base_url,
                    api_key=self.api_key
                )
            except ImportError:
                print("è­¦å‘Š: openai åº“æœªå®‰è£…ï¼Œå¯ç”¨ Mock æ¨¡å¼")
                self.mock_mode = True
    
    def analyze(self, df: pd.DataFrame, top_users: List[dict]) -> dict:
        """
        æ‰§è¡Œ AI åˆ†æã€‚
        
        å‚æ•°:
            df: æ¶ˆæ¯æ•°æ® DataFrame
            top_users: æ´»è·ƒç”¨æˆ·åˆ—è¡¨
            
        è¿”å›:
            AI åˆ†æç»“æœå­—å…¸
        """
        if self.mock_mode:
            return self._mock_analyze(top_users)
        
        # é‡‡æ ·æ¶ˆæ¯ç”¨äºåˆ†æ
        sampled_messages = self._sample_messages(df)
        
        # æ„å»ºåˆ†ææç¤º
        prompt = self._build_prompt(sampled_messages, top_users)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ¸©æš–æœ‰è¶£çš„ç¾¤èŠå›å¿†å®˜ï¼Œæ“…é•¿å‘ç°æœ‹å‹é—´çš„æ¸©é¦¨æ—¶åˆ»ã€‚ä½ çš„æŠ¥å‘Šæ€»æ˜¯å……æ»¡æ­£èƒ½é‡ï¼Œè®©æ¯ä¸ªäººéƒ½æ„Ÿåˆ°è¢«é‡è§†å’Œå–œçˆ±ã€‚ç»å¯¹ä¸è¦è¾“å‡ºä»»ä½•è´Ÿé¢ã€æ•æ„Ÿæˆ–å¯èƒ½å¼•èµ·äº‰è®®çš„å†…å®¹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            # å…¼å®¹ä¸åŒçš„å“åº”æ ¼å¼
            content = self._extract_content(response)
            if not content:
                raise ValueError("æ— æ³•ä»å“åº”ä¸­æå–å†…å®¹")
            
            return self._parse_response(content, top_users)
            
        except Exception as e:
            print(f"AI åˆ†æå¤±è´¥: {e}ï¼Œä½¿ç”¨ Mock æ•°æ®")
            return self._mock_analyze(top_users)
    
    def _sample_messages(self, df: pd.DataFrame, per_month: int = 8, min_length: int = 5) -> List[dict]:
        """
        æŒ‰æœˆå‡åŒ€é‡‡æ ·æ¶ˆæ¯ï¼Œç¡®ä¿æ—¶é—´åˆ†å¸ƒå‡è¡¡ã€‚
        
        å‚æ•°:
            df: æ¶ˆæ¯ DataFrame
            per_month: æ¯æœˆé‡‡æ ·æ¶ˆæ¯æ•°ï¼ˆç¡®ä¿æ—¶é—´å‡åŒ€åˆ†å¸ƒï¼‰
            min_length: æœ€å°æ¶ˆæ¯é•¿åº¦
        """
        sampled = []
        
        # æ·»åŠ æœˆä»½åˆ—
        df = df.copy()
        df['month'] = df['date'].str[:7]  # YYYY-MM
        
        # æŒ‰æœˆä»½åˆ†ç»„é‡‡æ ·
        for month, group in df.groupby('month'):
            # è¿‡æ»¤è¾ƒé•¿çš„æ¶ˆæ¯
            long_messages = group[group['content'].str.len() > min_length]
            
            if long_messages.empty:
                continue
            
            # æ¯æœˆå‡åŒ€é‡‡æ ·
            sample_size = min(per_month, len(long_messages))
            month_sample = long_messages.sample(n=sample_size)
            
            for _, row in month_sample.iterrows():
                # æˆªæ–­æ¶ˆæ¯é•¿åº¦ï¼Œé¿å…è¿‡é•¿å†…å®¹è§¦å‘å®¡æ ¸
                content = self._sanitize_content(row['content'])
                if len(content) > 80:
                    content = content[:80] + '...'
                sampled.append({
                    'user': row['user'],
                    'content': content,
                    'date': row['date']
                })
        
        return sampled
    
    def _sanitize_content(self, text: str) -> str:
        """
        éšç§è„±æ•ï¼šæ›¿æ¢æ‰‹æœºå·ç­‰æ•æ„Ÿä¿¡æ¯ã€‚
        """
        # æ›¿æ¢æ‰‹æœºå·
        text = re.sub(r'1[3-9]\d{9}', '138****0000', text)
        # æ›¿æ¢é‚®ç®±
        text = re.sub(r'[\w.-]+@[\w.-]+\.\w+', '***@**.com', text)
        # æ›¿æ¢èº«ä»½è¯å·
        text = re.sub(r'\d{17}[\dXx]', '****', text)
        
        return text
    
    def _build_prompt(self, messages: List[dict], top_users: List[dict]) -> str:
        """
        æ„å»ºåˆ†ææç¤ºè¯ã€‚
        """
        # æŒ‰æœˆä»½æ•´ç†æ¶ˆæ¯
        from collections import defaultdict
        monthly_msgs = defaultdict(list)
        for m in messages:
            month = m['date'][:7]  # YYYY-MM
            monthly_msgs[month].append(m)
        
        # æ ¼å¼åŒ–æŒ‰æœˆæ¶ˆæ¯ï¼ˆæ¯æœˆæœ€å¤š10æ¡ï¼‰
        msg_sections = []
        for month in sorted(monthly_msgs.keys()):
            month_num = int(month.split('-')[1])
            month_name = f"{month_num}æœˆ"
            month_messages = monthly_msgs[month][:10]
            msg_text = "\n".join([
                f"  - {m['user']}: {m['content']}"
                for m in month_messages
            ])
            msg_sections.append(f"### {month_name}\n{msg_text}")
        
        all_msg_text = "\n\n".join(msg_sections)
        
        # æ ¼å¼åŒ–æ‰€æœ‰ç”¨æˆ·ï¼ˆç”¨äºäººç‰©ç”»åƒï¼‰
        all_user_names = [u['user'] for u in top_users]
        
        # ç”Ÿæˆæœˆä»½åˆ—è¡¨
        months_list = [f"{int(m.split('-')[1])}æœˆ" for m in sorted(monthly_msgs.keys())]
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹å¾®ä¿¡ç¾¤èŠè®°å½•ï¼Œç”Ÿæˆä¸€ä»½æ¸©é¦¨æœ‰è¶£çš„å¹´åº¦ç¾¤èŠæŠ¥å‘Šã€‚

## ç¾¤èŠæ¶ˆæ¯æ ·æœ¬ï¼ˆæŒ‰æœˆæ•´ç†ï¼‰:
{all_msg_text}

## ç¾¤æˆå‘˜åˆ—è¡¨: {', '.join(all_user_names)}
## åŒ…å«æœˆä»½: {', '.join(months_list)}

---

## åˆ†æä»»åŠ¡

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡º Markdown æŠ¥å‘Šï¼š

### ğŸ¯ ç¾¤èŠå¹´åº¦å…³é”®è¯
ç”¨ 3 ä¸ª**ç§¯ææ­£å‘**çš„å…³é”®è¯æ€»ç»“è¿™ä¸ªç¾¤çš„æ°›å›´ï¼ˆå¦‚ï¼šæ¬¢ä¹ã€äº’åŠ©ã€æ¸©æš–ç­‰ï¼‰ã€‚

### ğŸ‘¥ ç¾¤å‹ç”»åƒå¢™
ä¸º**æ¯ä¸€ä½**ç¾¤æˆå‘˜ç”Ÿæˆä¸€å¥è¯æ­£å‘ç”»åƒï¼ˆåŒ…æ‹¬ï¼š{', '.join(all_user_names)}ï¼‰ã€‚
- ç”¨å¯çˆ±/æ¸©æš–/å¹½é»˜çš„è¯­æ°”
- çªå‡ºæ¯ä¸ªäººçš„é—ªå…‰ç‚¹å’Œè´¡çŒ®
- ç»™æ¯äººä¸€ä¸ªæœ‰è¶£çš„"ç§°å·"ï¼ˆå¦‚ï¼šè¡¨æƒ…åŒ…å¤§å¸ˆã€æš–å¿ƒæ‹…å½“ã€æ°”æ°›ç»„ç»„é•¿ç­‰ï¼‰

### ğŸ“… æœˆåº¦è¯é¢˜å›é¡¾
è¯·ä¸º**æ¯ä¸€ä¸ªæœˆ**ï¼ˆ{', '.join(months_list)}ï¼‰éƒ½ç”Ÿæˆè¯¦ç»†çš„è¯é¢˜å›é¡¾ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

**ğŸ“Œ 1æœˆ**
- ğŸ”¹ è¯é¢˜1ï¼šç®€çŸ­æè¿°ï¼ˆ1-2å¥è¯è¯´æ˜å¤§å®¶èŠäº†ä»€ä¹ˆï¼‰
- ğŸ”¹ è¯é¢˜2ï¼šç®€çŸ­æè¿°
- ğŸ”¹ è¯é¢˜3ï¼šç®€çŸ­æè¿°

**ğŸ“Œ 2æœˆ**
...ï¼ˆä»¥æ­¤ç±»æ¨ï¼Œæ¯ä¸ªæœˆéƒ½è¦æœ‰ 2-4 ä¸ªè¯é¢˜ï¼‰

**âš ï¸ æ¯ä¸ªæœˆéƒ½å¿…é¡»æœ‰å†…å®¹ï¼Œä¸èƒ½è·³è¿‡ä»»ä½•æœˆä»½ï¼**

### âœ¨ å¹´åº¦æ¸©é¦¨æ—¶åˆ»
æŒ‘é€‰ 2-3 ä¸ª**æ¸©é¦¨æœ‰è¶£**çš„ç¾¤èŠç‰‡æ®µæˆ–äº’åŠ¨åœºæ™¯ã€‚

---

## âš ï¸ é‡è¦è§„åˆ™
1. **åªè¾“å‡ºç§¯ææ­£å‘çš„å†…å®¹**ï¼Œå±•ç°ç¾¤å‹é—´çš„å‹è°Šå’Œæ¬¢ä¹
2. **é¿å¼€ä»»ä½•æ•æ„Ÿè¯é¢˜**ï¼ˆå¦‚æ„Ÿæƒ…é—®é¢˜ã€ä¸ªäººéšç§ã€äº‰åµç­‰ï¼‰
3. **è¯­æ°”è¦æ¸©æš–æœ‰è¶£**ï¼Œåƒæ˜¯è€æœ‹å‹ä¹‹é—´çš„å¹´ç»ˆæš–å¿ƒå›é¡¾
4. **æ¯ä¸ªäººéƒ½è¦æœ‰ç”»åƒ**ï¼Œä¸èƒ½é—æ¼ä»»ä½•ç¾¤æˆå‘˜
5. **æ¯ä¸ªæœˆéƒ½è¦æœ‰è¯é¢˜å›é¡¾**ï¼Œä¸èƒ½è·³è¿‡ä»»ä½•æœˆä»½
6. å¦‚æœæ¶ˆæ¯ä¸­æœ‰ä¸é€‚åˆå…¬å¼€çš„å†…å®¹ï¼Œç”¨"æ—¥å¸¸è¶£äº‹"ç­‰æ¦‚æ‹¬æ€§æè¿°æ›¿ä»£
"""
        return prompt
    
    def _extract_content(self, response) -> str:
        """
        ä»ä¸åŒæ ¼å¼çš„ API å“åº”ä¸­æå–å†…å®¹ã€‚
        æ”¯æŒï¼šOpenAI æ ‡å‡†æ ¼å¼ã€å­—ç¬¦ä¸²ã€å­—å…¸ç­‰å¤šç§æ ¼å¼ã€‚
        """
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
        if isinstance(response, str):
            return response
        
        # æ ‡å‡† OpenAI æ ¼å¼
        if hasattr(response, 'choices') and response.choices:
            choice = response.choices[0]
            if hasattr(choice, 'message') and hasattr(choice.message, 'content'):
                return choice.message.content
            if hasattr(choice, 'text'):
                return choice.text
        
        # å­—å…¸æ ¼å¼
        if isinstance(response, dict):
            # OpenAI æ ¼å¼çš„å­—å…¸
            if 'choices' in response and response['choices']:
                choice = response['choices'][0]
                if isinstance(choice, dict):
                    if 'message' in choice and 'content' in choice['message']:
                        return choice['message']['content']
                    if 'text' in choice:
                        return choice['text']
            # ç›´æ¥æœ‰ content å­—æ®µ
            if 'content' in response:
                return response['content']
            # ç›´æ¥æœ‰ text å­—æ®µ
            if 'text' in response:
                return response['text']
        
        # å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        return str(response) if response else None
    
    def _parse_response(self, content: str, top_users: List[dict]) -> dict:
        """
        è§£æ AI å“åº”ã€‚
        """
        return {
            'raw_content': content,
            'keywords': self._extract_keywords(content),
            'user_profiles': self._extract_user_profiles(content, top_users),
            'topics': self._extract_topics(content),
            'highlights': self._extract_highlights(content),
        }
    
    def _extract_keywords(self, content: str) -> List[str]:
        """å°è¯•ä»å†…å®¹ä¸­æå–å…³é”®è¯"""
        # ç®€å•å®ç°ï¼Œå®é™…å¯ä»¥ç”¨æ›´ç²¾ç¡®çš„åŒ¹é…
        keywords = ['æ¬¢ä¹', 'åæ§½', 'äº’åŠ©']
        return keywords
    
    def _extract_user_profiles(self, content: str, top_users: List[dict]) -> List[dict]:
        """å°è¯•æå–ç”¨æˆ·ç”»åƒ"""
        profiles = []
        for user in top_users[:3]:
            profiles.append({
                'user': user['user'],
                'description': 'ç¾¤å†…æ´»è·ƒåˆ†å­ï¼Œè¯é¢˜å‘èµ·è€…'
            })
        return profiles
    
    def _extract_topics(self, content: str) -> List[str]:
        """å°è¯•æå–è¯é¢˜"""
        return ['æ—¥å¸¸é—²èŠ', 'å·¥ä½œåæ§½', 'ç”Ÿæ´»åˆ†äº«']
    
    def _extract_highlights(self, content: str) -> str:
        """æå–ç²¾å½©ç‰‡æ®µ"""
        return 'ç¾¤å‹ä»¬çš„æ—¥å¸¸æ¬¢ä¹æ—¶å…‰~'
    
    def _mock_analyze(self, top_users: List[dict]) -> dict:
        """
        Mock æ¨¡å¼ï¼šè¿”å›æ¨¡æ‹Ÿæ•°æ®ã€‚
        """
        user_names = [u['user'] for u in top_users[:3]]
        
        mock_content = f"""## ğŸ¯ ç¾¤èŠå¹´åº¦å…³é”®è¯

**æ¬¢ä¹** | **åæ§½** | **äº’å¸®äº’åŠ©**

è¿™æ˜¯ä¸€ä¸ªå……æ»¡æ¬¢å£°ç¬‘è¯­çš„ç¾¤èŠï¼Œç¾¤å‹ä»¬åœ¨è¿™é‡Œåˆ†äº«ç”Ÿæ´»ã€åæ§½å·¥ä½œã€äº’ç›¸å¸®åŠ©ã€‚

---

## ğŸ‘¥ æ´»è·ƒæˆå‘˜ç”»åƒ

{"" if not user_names else f'''
### ğŸ¥‡ {user_names[0] if len(user_names) > 0 else "ç¥ç§˜äºº"}
ç¾¤å†…è¯ç—¨æ‹…å½“ï¼Œæ¯å¤©å‡†æ—¶æŠ¥åˆ°ï¼Œæ˜¯ç¾¤é‡Œçš„æ°”æ°›ç»„ç»„é•¿ã€‚å‘è¨€é£æ ¼å¹½é»˜é£è¶£ï¼Œç»å¸¸èƒ½æŠŠå¤§å®¶é€—ä¹ã€‚

### ğŸ¥ˆ {user_names[1] if len(user_names) > 1 else "éšè—å¤§ä½¬"}
æ·±å¤œå†²æµªé€‰æ‰‹ï¼Œæ“…é•¿åœ¨å‡Œæ™¨å‘è¡¨äººç”Ÿæ„Ÿæ‚Ÿã€‚å¶å°”å†’æ³¡ï¼Œå¥å¥ç»å…¸ã€‚

### ğŸ¥‰ {user_names[2] if len(user_names) > 2 else "æ½œæ°´è¾¾äºº"}
è¡¨æƒ…åŒ…å¤§å¸ˆï¼Œæ€»èƒ½åœ¨å…³é”®æ—¶åˆ»ç”©å‡ºå®Œç¾çš„è¡¨æƒ…åŒ…æ•‘åœºã€‚
'''}

---

## ğŸ”¥ çƒ­é—¨è¯é¢˜

1. **æ—¥å¸¸æ‰“å¡** - æ—©å®‰æ™šå®‰é—®å€™ä»æœªæ–­è¿‡
2. **ç¾é£Ÿåˆ†äº«** - æ·±å¤œæ”¾æ¯’ï¼Œå‡è‚¥è·¯ä¸Šçš„ç»Šè„šçŸ³
3. **å·¥ä½œåæ§½** - æ‰“å·¥äººçš„å¿ƒé…¸ï¼Œåªæœ‰ç¾¤å‹æ‡‚
4. **æ¸¸æˆå¼€é»‘** - ä¸€èµ·ä¸Šåˆ†ï¼Œä¸€èµ·æ‰åˆ†
5. **ç”Ÿæ´»çäº‹** - å®¶é•¿é‡ŒçŸ­ï¼Œæ¸©æš–æ—¥å¸¸

---

## âœ¨ ç¾¤èŠååœºé¢

> "ä»Šå¹´æœ€éš¾å¿˜çš„ä¸€åˆ»ï¼Œå¤§æ¦‚æ˜¯æŸä½ç¾¤å‹å‡Œæ™¨ä¸‰ç‚¹è¿˜åœ¨ç¾¤é‡Œå‘æ¶ˆæ¯ï¼Œç»“æœç¬¬äºŒå¤©ä¸Šç­è¿Ÿåˆ°è¢«è€æ¿éª‚äº†..."

ç¾¤èŠè™½ç„¶è¯ä¸å¤šï¼Œä½†æ¯ä¸€å¥éƒ½æ˜¯æ„Ÿæƒ…ã€‚è¿™ä¸€å¹´ï¼Œæ„Ÿè°¢æœ‰ä½ ä»¬çš„é™ªä¼´ï¼ğŸ‰

---

*ï¼ˆä»¥ä¸Šåˆ†æç”± AI è‡ªåŠ¨ç”Ÿæˆï¼Œå¦‚æœ‰é›·åŒï¼Œçº¯å±å·§åˆï¼‰*
"""
        
        return {
            'raw_content': mock_content,
            'keywords': ['æ¬¢ä¹', 'åæ§½', 'äº’å¸®äº’åŠ©'],
            'user_profiles': [
                {'user': user_names[0] if user_names else 'ç”¨æˆ·1', 'description': 'ç¾¤å†…è¯ç—¨æ‹…å½“'},
                {'user': user_names[1] if len(user_names) > 1 else 'ç”¨æˆ·2', 'description': 'æ·±å¤œå†²æµªé€‰æ‰‹'},
                {'user': user_names[2] if len(user_names) > 2 else 'ç”¨æˆ·3', 'description': 'è¡¨æƒ…åŒ…å¤§å¸ˆ'},
            ],
            'topics': ['æ—¥å¸¸æ‰“å¡', 'ç¾é£Ÿåˆ†äº«', 'å·¥ä½œåæ§½', 'æ¸¸æˆå¼€é»‘', 'ç”Ÿæ´»çäº‹'],
            'highlights': 'ä»Šå¹´æœ€éš¾å¿˜çš„ä¸€åˆ»...',
            'is_mock': True
        }
    
    def summarize_clusters(self, cluster_representatives: dict) -> dict:
        """
        ä½¿ç”¨ LLM ä¸ºèšç±»ç”Ÿæˆæœ‰æ„ä¹‰çš„è¯é¢˜åç§°ã€‚
        
        å‚æ•°:
            cluster_representatives: æ¯ä¸ªèšç±»çš„ä»£è¡¨æ€§æ¶ˆæ¯
                {0: [{'content': '...', 'user': '...'}, ...], 1: [...], ...}
                
        è¿”å›:
            è¯é¢˜åç§°å­—å…¸ {0: 'è¯é¢˜å', 1: 'è¯é¢˜å', ...}
        """
        if self.mock_mode:
            return self._mock_summarize_clusters(cluster_representatives)
        
        # æ„å»º Prompt
        prompt = self._build_cluster_prompt(cluster_representatives)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªç¾¤èŠè¯é¢˜åˆ†ç±»ä¸“å®¶ã€‚è¯·æ ¹æ®æä¾›çš„æ¶ˆæ¯æ ·æœ¬ï¼Œä¸ºæ¯ä¸ªè¯é¢˜ç»„èµ·ä¸€ä¸ªç®€çŸ­æœ‰è¶£çš„åå­—ï¼ˆ2-6ä¸ªå­—ï¼‰ã€‚"
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            # å…¼å®¹ä¸åŒçš„å“åº”æ ¼å¼
            content = self._extract_content(response)
            if not content:
                raise ValueError("æ— æ³•ä»å“åº”ä¸­æå–å†…å®¹")
            
            return self._parse_cluster_names(content, cluster_representatives)
            
        except Exception as e:
            print(f"   âš ï¸ è¯é¢˜å‘½åå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤åç§°")
            return self._mock_summarize_clusters(cluster_representatives)
    
    def _build_cluster_prompt(self, cluster_representatives: dict) -> str:
        """æ„å»ºèšç±»å‘½åçš„æç¤ºè¯ã€‚"""
        lines = ["ä»¥ä¸‹æ˜¯é€šè¿‡å‘é‡ç®—æ³•è‡ªåŠ¨èšç±»çš„ç¾¤èŠæ¶ˆæ¯ç»„ï¼Œè¯·ä¸ºæ¯ç»„èµ·ä¸€ä¸ªç®€çŸ­æœ‰è¶£çš„åå­—ã€‚\n"]
        
        for cluster_id, messages in cluster_representatives.items():
            if not messages:
                continue
            
            lines.append(f"## åˆ†ç»„ {cluster_id}")
            for msg in messages[:5]:  # æ¯ç»„æœ€å¤šå±•ç¤º5æ¡
                content = msg['content'][:50]  # æˆªæ–­é•¿å†…å®¹
                lines.append(f"- {msg['user']}: {content}")
            lines.append("")
        
        lines.append("""
è¯·è¿”å› JSON æ ¼å¼çš„ç»“æœï¼Œä¾‹å¦‚ï¼š
{"0": "åˆé¤æ‹¼å•", "1": "æŠ€æœ¯äº¤æµ", "2": "æ‘¸é±¼æ—¶é—´"}

æ³¨æ„ï¼š
- åå­—è¦ç®€çŸ­ï¼ˆ2-6ä¸ªå­—ï¼‰
- å¯ä»¥å¹½é»˜æœ‰è¶£
- è¦èƒ½åæ˜ è¯¥ç»„æ¶ˆæ¯çš„ä¸»é¢˜""")
        
        return "\n".join(lines)
    
    def _parse_cluster_names(self, content: str, cluster_representatives: dict) -> dict:
        """è§£æ LLM è¿”å›çš„è¯é¢˜åç§°ã€‚"""
        import json
        
        # å°è¯•æå– JSON
        try:
            # å°è¯•ç›´æ¥è§£æ
            names = json.loads(content)
            return {int(k): v for k, v in names.items()}
        except:
            pass
        
        # å°è¯•ä»æ–‡æœ¬ä¸­æå– JSON å—
        import re
        json_match = re.search(r'\{[^{}]+\}', content)
        if json_match:
            try:
                names = json.loads(json_match.group())
                return {int(k): v for k, v in names.items()}
            except:
                pass
        
        # å¤±è´¥åˆ™è¿”å›é»˜è®¤åç§°
        return self._mock_summarize_clusters(cluster_representatives)
    
    def _mock_summarize_clusters(self, cluster_representatives: dict) -> dict:
        """Mock æ¨¡å¼ï¼šè¿”å›é»˜è®¤è¯é¢˜åç§°ã€‚"""
        default_names = [
            "æ—¥å¸¸é—²èŠ", "æŠ€æœ¯äº¤æµ", "åˆé¤æ‹¼å•",
            "åæ§½å¤§ä¼š", "è¡¨æƒ…åŒ…äº’åŠ¨", "æ·±å¤œemo",
            "æ‘¸é±¼æ—¶é—´", "å‘¨æœ«è®¡åˆ’", "ç”Ÿæ´»åˆ†äº«"
        ]
        
        result = {}
        for i, cluster_id in enumerate(cluster_representatives.keys()):
            name = default_names[i % len(default_names)]
            result[cluster_id] = name
        
        return result
    
    def select_golden_quotes(self, hot_messages: list) -> list:
        """
        ä½¿ç”¨ AI ä»çƒ­é—¨æ¶ˆæ¯ä¸­ç”„é€‰é‡‘å¥ã€‚
        
        å‚æ•°:
            hot_messages: çƒ­é—¨æ¶ˆæ¯åˆ—è¡¨ï¼ˆæ¥è‡ª stats_engineï¼‰
            
        è¿”å›:
            [{'user': 'ç”¨æˆ·', 'content': 'é‡‘å¥', 'reason': 'å…¥é€‰ç†ç”±'}, ...]
        """
        if not hot_messages:
            return []
        
        if self.mock_mode:
            return self._mock_golden_quotes(hot_messages)
        
        # æ‰©å¤§å€™é€‰èŒƒå›´ï¼Œé€‰å–æ›´å¤šæ¶ˆæ¯ä¾› AI ç­›é€‰
        candidates = hot_messages[:30]
        msg_text = "\n".join([
            f"{i+1}. [{m['user']}]: {m['content']}"
            for i, m in enumerate(candidates)
        ])
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¾¤èŠ"é‡‘å¥æŒ–æ˜å¸ˆ"ã€‚è¯·ä»ä»¥ä¸‹ç¾¤èŠæ¶ˆæ¯ä¸­ï¼Œç²¾é€‰å‡ºæœ€å€¼å¾—è®°ä½çš„"å¹´åº¦é‡‘å¥"ã€‚

## å€™é€‰æ¶ˆæ¯ï¼š
{msg_text}

## ä»»åŠ¡è¦æ±‚ï¼š
è¯·æŒ‘é€‰ **8-12 æ¡** æœ€ç²¾å½©çš„é‡‘å¥ï¼Œåˆ†ä¸ºä»¥ä¸‹ç±»åˆ«ï¼š

### ç±»åˆ«è¯´æ˜ï¼š
- ğŸ˜‚ **æç¬‘æ‹…å½“**ï¼šæœ€è®©äººæ§è…¹çš„è¯
- ğŸ’¡ **é‡‘ç‰è‰¯è¨€**ï¼šæœ‰é“ç†ã€æœ‰æ·±åº¦çš„è¯
- ğŸ”¥ **ååœºé¢**ï¼šå¼•å‘çƒ­çƒˆè®¨è®ºçš„è¯
- ğŸ’– **æš–å¿ƒæ—¶åˆ»**ï¼šæ¸©æš–äººå¿ƒçš„è¯
- ğŸ­ **ç¥å›å¤**ï¼šç¥çº§å›å¤ã€åè½¬ã€åæ§½

## è¾“å‡ºæ ¼å¼ï¼ˆJSON æ•°ç»„ï¼‰ï¼š
[
  {{"user": "ç”¨æˆ·å", "content": "å®Œæ•´é‡‘å¥å†…å®¹", "reason": "å…¥é€‰ç†ç”±ï¼ˆ10å­—å†…ï¼‰", "category": "ç±»åˆ«æ ‡ç­¾"}}
]

## æ³¨æ„ï¼š
- ä¼˜å…ˆé€‰æ‹©æœ‰è¶£ã€æ­£å‘ã€æœ‰åˆ›æ„çš„å†…å®¹
- æ¯ä¸ªç±»åˆ«è‡³å°‘é€‰ 1 æ¡
- é¿å…ä»»ä½•æ•æ„Ÿæˆ–è´Ÿé¢å†…å®¹
- é‡‘å¥å†…å®¹ä¿æŒåŸæ ·ï¼Œä¸è¦ä¿®æ”¹"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¾¤èŠé‡‘å¥æŒ–æ˜å¸ˆï¼Œæ“…é•¿å‘ç°ç¾¤é‡Œæœ€ç²¾å½©ã€æœ€æœ‰è¶£ã€æœ€æ¸©æš–çš„è¯è¯­ã€‚ä½ çš„å®¡ç¾å¾ˆå¥½ï¼Œå–„äºæŠ“ä½é‡ç‚¹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1500
            )
            
            content = self._extract_content(response)
            return self._parse_golden_quotes(content, candidates)
            
        except Exception as e:
            print(f"   âš ï¸ é‡‘å¥ç”„é€‰å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤")
            return self._mock_golden_quotes(hot_messages)
    
    def _parse_golden_quotes(self, content: str, candidates: list) -> list:
        """è§£æ AI è¿”å›çš„é‡‘å¥ã€‚"""
        import json
        
        try:
            # å°è¯•æå– JSON æ•°ç»„
            import re
            json_match = re.search(r'\[.*\]', content, re.DOTALL)
            if json_match:
                quotes = json.loads(json_match.group())
                return quotes[:5]
        except:
            pass
        
        return self._mock_golden_quotes(candidates)
    
    def _mock_golden_quotes(self, hot_messages: list) -> list:
        """Mock æ¨¡å¼ï¼šè¿”å›æ¨¡æ‹Ÿé‡‘å¥ã€‚"""
        quotes = []
        for msg in hot_messages[:3]:
            quotes.append({
                'user': msg['user'],
                'content': msg['content'][:50],
                'reason': 'å¼•å‘çƒ­çƒˆè®¨è®º'
            })
        return quotes
    
    def summarize_peak_day(self, peak_day_data: dict) -> str:
        """
        ä¸ºå·…å³°æ—¥ç”Ÿæˆ 50 å­—æ‘˜è¦ã€‚
        
        å‚æ•°:
            peak_day_data: {'date': 'æ—¥æœŸ', 'count': æ•°é‡, 'sample_messages': [...]}
            
        è¿”å›:
            50 å­—å·¦å³çš„æ‘˜è¦
        """
        if not peak_day_data or not peak_day_data.get('date'):
            return "è¿™ä¸€å¤©ï¼Œç¾¤é‡Œæ ¼å¤–çƒ­é—¹ï¼Œå¤§å®¶ç•…æ‰€æ¬²è¨€..."
        
        if self.mock_mode:
            return f"é‚£ä¸€å¤©ï¼ˆ{peak_day_data['date']}ï¼‰ï¼Œç¾¤é‡Œå…±äº§ç”Ÿäº† {peak_day_data['count']} æ¡æ¶ˆæ¯ï¼Œå¤§å®¶èŠå¾—æ ¼å¤–å¼€å¿ƒï¼Œè¯é¢˜ä¸€ä¸ªæ¥ä¸€ä¸ªåœä¸ä¸‹æ¥ï¼"
        
        # æ„å»ºæ ·æœ¬æ¶ˆæ¯æ–‡æœ¬
        samples = peak_day_data.get('sample_messages', [])
        msg_text = "\n".join([
            f"- {m['user']}: {m['content'][:30]}"
            for m in samples[:5]
        ])
        
        prompt = f"""è¿™æ˜¯ç¾¤é‡Œæ¶ˆæ¯æœ€å¤šçš„ä¸€å¤©ï¼ˆ{peak_day_data['date']}ï¼Œå…± {peak_day_data['count']} æ¡æ¶ˆæ¯ï¼‰çš„éƒ¨åˆ†æ¶ˆæ¯ï¼š

{msg_text}

è¯·ç”¨ 50 å­—å·¦å³ï¼Œæ¸©é¦¨æœ‰è¶£åœ°æè¿°"é‚£ä¸€å¤©å¤§å®¶éƒ½åœ¨èŠä»€ä¹ˆ"ã€‚
å¼€å¤´ç”¨"é‚£ä¸€å¤©ï¼Œ"ä½œä¸ºå¼•å­ã€‚ä¸è¦æåŠä»»ä½•æ•æ„Ÿå†…å®¹ã€‚"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ¸©é¦¨çš„ç¾¤èŠå›å¿†å®˜ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=100
            )
            
            content = self._extract_content(response)
            return content.strip() if content else self._mock_peak_day_summary(peak_day_data)
            
        except Exception as e:
            print(f"   âš ï¸ å·…å³°æ—¥æ‘˜è¦å¤±è´¥: {e}")
            return self._mock_peak_day_summary(peak_day_data)
    
    def _mock_peak_day_summary(self, peak_day_data: dict) -> str:
        """Mock æ¨¡å¼ï¼šè¿”å›é»˜è®¤å·…å³°æ—¥æ‘˜è¦ã€‚"""
        return f"é‚£ä¸€å¤©ï¼ˆ{peak_day_data.get('date', 'æŸå¤©')}ï¼‰ï¼Œç¾¤é‡Œäº§ç”Ÿäº† {peak_day_data.get('count', 0)} æ¡æ¶ˆæ¯ï¼Œæ¬¢å£°ç¬‘è¯­ä¸æ–­ï¼Œå‹è°Šåœ¨è¿™é‡Œå‡æ¸©ï¼"
    
    def generate_topic_memories(self, monthly_data: list) -> list:
        """
        ä¸ºæ¯ä¸ªæœˆç”Ÿæˆè¯é¢˜å›å¿†æè¿°ã€‚
        
        å‚æ•°:
            monthly_data: æœˆåº¦åˆ†ææ•°æ®åˆ—è¡¨ï¼ˆæ¥è‡ª monthly_analyzerï¼‰
            
        è¿”å›:
            [{'month': '1æœˆ', 'topics': [...], 'memory': 'å›å¿†æè¿°'}, ...]
        """
        if not monthly_data:
            return []
        
        results = []
        
        for month_info in monthly_data:
            # è·å–æœ¬æœˆæ ·æœ¬æ¶ˆæ¯
            samples = month_info.get('sample_messages', [])
            old_topics = month_info.get('topics', [])
            
            if self.mock_mode or not samples:
                ai_result = {
                    'topics': [],
                    'memory': self._mock_topic_memory(month_info)
                }
            else:
                ai_result = self._generate_month_memory(month_info, samples, old_topics)
            
            results.append({
                'month': month_info.get('month_name', ''),
                'month_key': month_info.get('month', ''),
                'topics': ai_result.get('topics', []),  # AI æå–çš„å…·ä½“è¯é¢˜
                'memory': ai_result.get('memory', ''),
                'stats': month_info.get('stats', {})
            })
        
        return results
    
    def _generate_month_memory(self, month_info: dict, samples: list, topics: list) -> dict:
        """ä½¿ç”¨ AI ç”Ÿæˆå•æœˆè¯é¢˜å›å¿†å’Œå…·ä½“è¯é¢˜åˆ—è¡¨ã€‚"""
        month_name = month_info.get('month_name', 'æœ¬æœˆ')
        
        # æ„å»ºæ¶ˆæ¯æ ·æœ¬ï¼ˆå¢åŠ æ•°é‡ï¼‰
        msg_text = "\n".join([
            f"- {m['user']}: {m['content'][:60]}"
            for m in samples[:15]
        ])
        
        prompt = f"""è¯·åˆ†æç¾¤èŠçš„ {month_name} æ¶ˆæ¯ï¼Œæå–å…·ä½“è¯é¢˜ã€‚

## æœ¬æœˆæ¶ˆæ¯æ ·æœ¬ï¼š
{msg_text}

## ä»»åŠ¡ï¼š
1. æå– 3-5 ä¸ªæœ¬æœˆ**å…·ä½“å‘ç”Ÿçš„è¯é¢˜/äº‹ä»¶**ï¼ˆä¸æ˜¯å•è¯ï¼Œè€Œæ˜¯å…·ä½“çš„äº‹æƒ…ï¼‰
2. å†™ä¸€æ®µ 80-100 å­—çš„æœˆåº¦å›å¿†

## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼JSONï¼‰ï¼š
{{
  "topics": [
    {{"title": "è¯é¢˜æ ‡é¢˜ï¼ˆ4-8å­—ï¼‰", "desc": "ä¸€å¥è¯æè¿°"}},
    ...
  ],
  "memory": "è¿™ä¸ªæœˆï¼Œ..."
}}

## ç¤ºä¾‹ï¼š
{{
  "topics": [
    {{"title": "å°æ˜ç”Ÿæ—¥èšä¼š", "desc": "å¤§å®¶ç»™å°æ˜åº†ç”Ÿï¼Œçƒ­é—¹éå‡¡"}},
    {{"title": "å¹´åº•åŠ ç­åæ§½", "desc": "é›†ä½“åæ§½åŠ ç­ï¼Œäº’ç›¸æ‰“æ°”"}},
    {{"title": "è·¨å¹´è®¡åˆ’è®¨è®º", "desc": "å•†é‡å»å“ªè·¨å¹´"}}
  ],
  "memory": "è¿™ä¸ªæœˆï¼Œå¤§å®¶ä¸€èµ·ç»™å°æ˜åº†ç¥äº†ç”Ÿæ—¥ï¼Œè¿˜é›†ä½“åæ§½äº†å¹´åº•åŠ ç­çš„è¾›è‹¦..."
}}

## è¦æ±‚ï¼š
- è¯é¢˜è¦**å…·ä½“**ï¼Œä¸è¦æ˜¯"æ—¥å¸¸é—²èŠ"è¿™æ ·ç¬¼ç»Ÿçš„
- ä»æ¶ˆæ¯å†…å®¹ä¸­æ¨æ–­å…·ä½“äº‹ä»¶
- å†…å®¹æ­£å‘æ¸©é¦¨ï¼Œé¿å…æ•æ„Ÿè¯é¢˜"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç¾¤èŠåˆ†æå¸ˆï¼Œæ“…é•¿ä»èŠå¤©è®°å½•ä¸­æå–å…·ä½“çš„è¯é¢˜äº‹ä»¶ã€‚åªè¾“å‡ºJSONæ ¼å¼ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            content = self._extract_content(response)
            
            # è§£æ JSON
            import json
            import re
            
            # å°è¯•æå– JSON
            json_match = re.search(r'\{[\s\S]*\}', content)
            if json_match:
                result = json.loads(json_match.group())
                return {
                    'topics': result.get('topics', []),
                    'memory': result.get('memory', self._mock_topic_memory(month_info))
                }
            else:
                return {
                    'topics': [],
                    'memory': content.strip() if content else self._mock_topic_memory(month_info)
                }
            
        except Exception as e:
            print(f"   âš ï¸ {month_name}è¯é¢˜æå–å¤±è´¥: {e}")
            return {
                'topics': [],
                'memory': self._mock_topic_memory(month_info)
            }
    
    def _mock_topic_memory(self, month_info: dict) -> str:
        """Mock æ¨¡å¼ï¼šè¿”å›é»˜è®¤è¯é¢˜å›å¿†ã€‚"""
        month_name = month_info.get('month_name', 'è¿™ä¸ªæœˆ')
        stats = month_info.get('stats', {})
        count = stats.get('total_messages', 0)
        
        templates = [
            f"è¿™ä¸ªæœˆï¼Œç¾¤é‡Œäº§ç”Ÿäº† {count} æ¡æ¶ˆæ¯ï¼Œå¤§å®¶èŠå¾—çƒ­ç«æœå¤©ï¼Œæ¬¢å£°ç¬‘è¯­ä¸æ–­ï¼",
            f"è¿™ä¸ªæœˆï¼Œ{count} æ¡æ¶ˆæ¯è®°å½•ç€æˆ‘ä»¬çš„æ—¥å¸¸ï¼Œæ¯ä¸€æ¡éƒ½æ˜¯å‹è°Šçš„è§è¯ã€‚",
            f"è¿™ä¸ªæœˆï¼Œæˆ‘ä»¬ç”¨ {count} æ¡æ¶ˆæ¯å¡«æ»¡äº†è¿™ä¸ªå°å¤©åœ°ï¼Œå¿«ä¹ä¸€ç›´åœ¨çº¿ï¼",
        ]
        import random
        return random.choice(templates)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    import sys
    from data_loader import load_chat_data
    from stats_engine import calculate_stats
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python ai_analyzer.py <json_file_path>")
        print("\næ³¨æ„: éœ€è¦é…ç½® .env æ–‡ä»¶ä¸­çš„ LLM_API_KEY")
        print("å¦‚æœæ²¡æœ‰é…ç½®ï¼Œå°†ä½¿ç”¨ Mock æ¨¡å¼è¿”å›æ¨¡æ‹Ÿæ•°æ®")
        sys.exit(1)
    
    file_path = sys.argv[1]
    
    try:
        df, session = load_chat_data(file_path)
        stats = calculate_stats(df)
        
        analyzer = AIAnalyzer()
        print(f"Mock æ¨¡å¼: {analyzer.mock_mode}")
        
        result = analyzer.analyze(df, stats['top_users'])
        
        print("\n=== AI åˆ†æç»“æœ ===")
        print(result['raw_content'])
        
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
